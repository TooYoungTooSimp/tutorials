{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ba230c",
   "metadata": {},
   "source": [
    "# Easy Agent Tutorial\n",
    "This notebook file provide three examples of using LLM based agents with different tool sets.\n",
    "\n",
    "prequisites:\n",
    "- Python 3.10+\n",
    "- Install required packages:\n",
    "  ```bash\n",
    "  pip install -r \"mcp[cli]\" smolagent\n",
    "  ```\n",
    "\n",
    "## Task Description\n",
    "\n",
    "如README所述，该项目应用三种方案，从不同的角度实现了agentic RAG的功能。为了演示，这一次我们将会构建一个信安四大会的查询，来进行感兴趣论文的搜索以及基于题目选择合适的会议进行投稿。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5058f",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "我们将使用dblp数据集来进行演示。首先下载四大会最近几年的会议论文数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a91a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0352eb4d",
   "metadata": {},
   "source": [
    "在开始之前，先看一下传统的工具调用大概长啥样，有怎样的优缺点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import re\n",
    "\n",
    "import dotenv\n",
    "import tenacity\n",
    "import yaml\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "from openai.types import *\n",
    "from openai.types.chat import *\n",
    "\n",
    "\n",
    "def raw_toolcall():\n",
    "    client = OpenAI()\n",
    "    db = FAISS.load_local(\n",
    "        \"faiss_db\",\n",
    "        OpenAIEmbeddings(),\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "    tools_def = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"name\": \"query_db\",\n",
    "            \"description\": \"accept keyword and return related information\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"kw\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The keyword to query the database\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"kw\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    def real_ask(question: str):\n",
    "        with open(\"keywords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            keywords = f.read().strip()\n",
    "        from openai.types.responses.response_input_param import Message\n",
    "\n",
    "        input_msgs: list[Message] = [\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"你是一名中石化新入职大学生，正在复习领导的讲座。讲座材料以听写转录的形式给出，注意同音字近音字的存在。必须调用函数（可多次）来进行关键词RAG检索，返回相关听写转录。参考关键词：{keywords}\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            },\n",
    "        ]\n",
    "        resp = client.responses.create(\n",
    "            model=\"gpt-5.1\",\n",
    "            tools=tools_def,\n",
    "            input=input_msgs,\n",
    "            tool_choice=\"required\",\n",
    "        )\n",
    "        print(resp.output)\n",
    "        for toolcall in resp.output:\n",
    "            if toolcall.type != \"function_call\":\n",
    "                continue\n",
    "            if toolcall.name == \"query_db\":\n",
    "                kw = json.loads(toolcall.arguments)[\"kw\"]\n",
    "                print(f\"Keyword: {kw}\")\n",
    "                docs = []\n",
    "                for skw in kw.split():\n",
    "                    if not (skw := skw.strip()):\n",
    "                        continue\n",
    "                    print(f\"Searching for keyword: {skw}\")\n",
    "                    docs.extend(db.similarity_search(skw, k=3))\n",
    "                rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "                input_msgs.append(toolcall)\n",
    "                input_msgs.append(\n",
    "                    {\n",
    "                        \"type\": \"function_call_output\",\n",
    "                        \"call_id\": toolcall.call_id,\n",
    "                        \"output\": str(rag_result),\n",
    "                    }\n",
    "                )\n",
    "                print(f\"{kw=} appended.\")\n",
    "        if input_msgs[-1][\"type\"] == \"function_call_output\":\n",
    "            resp = client.responses.create(\n",
    "                model=\"gpt-5.1\",\n",
    "                input=input_msgs,\n",
    "                # tools=tools_def,\n",
    "                stream=True,\n",
    "            )\n",
    "            for chunk in resp:\n",
    "                if chunk.type == \"response.output_text.delta\":\n",
    "                    print(chunk.delta, end=\"\", flush=True)\n",
    "            print()\n",
    "        else:\n",
    "            print(resp.output_text)\n",
    "\n",
    "    while True:\n",
    "        real_ask(input(\"=> \"))\n",
    "\n",
    "\n",
    "raw_toolcall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888af19",
   "metadata": {},
   "source": [
    "## SmolAgent::CodeAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d330b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from smolagents import CodeAgent, OpenAIServerModel, tool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    \"faiss_db\",\n",
    "    OpenAIEmbeddings(),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "\n",
    "with open(\"keywords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    keywords = f.read().strip()\n",
    "content = f\"$SYS_PROMPT\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_keywords() -> str:\n",
    "    \"\"\"\n",
    "    return the keywords for RAG search\n",
    "    \"\"\"\n",
    "    return \" \".join(keywords.split())\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_db(kw: str) -> str:\n",
    "    \"\"\"\n",
    "    accept keyword and return related information\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword to query the database\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for skw in kw.split():\n",
    "        if not (skw := skw.strip()):\n",
    "            continue\n",
    "        print(f\"Searching for keyword: {skw}\")\n",
    "        docs.extend(db.similarity_search(skw, k=3))\n",
    "    rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return rag_result\n",
    "\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model=OpenAIServerModel(\"gpt-5\"),\n",
    "    tools=[get_keywords, query_db],  # add your tools here (don't remove final_answer)\n",
    "    verbosity_level=1,\n",
    ")\n",
    "\n",
    "# from Gradio_UI import GradioUI\n",
    "\n",
    "# GradioUI(agent).launch()\n",
    "\n",
    "agent.run(f\"{content}\\n\\n$USER_PROMPT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
