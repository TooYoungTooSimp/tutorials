{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ba230c",
   "metadata": {},
   "source": [
    "# Easy Agent Tutorial\n",
    "This notebook file provide three examples of using LLM based agents with different tool sets.\n",
    "\n",
    "Prerequisites:\n",
    "- Python 3.10+\n",
    "- Install required packages:\n",
    "  ```bash\n",
    "  pip install requests python-dotenv langchain-community langchain-openai langchain langgraph \"smolagents[mcp, gradio]\" faiss-cpu tenacity pyyaml\n",
    "  ```\n",
    "\n",
    "## Task Description\n",
    "\n",
    "如README所述，该项目应用三种方案，从不同的角度实现了agentic RAG的功能。为了演示，这一次我们将会构建一个信安四大会的查询，来进行感兴趣论文的搜索以及基于题目选择合适的会议进行投稿。\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a91a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们将使用dblp数据集来进行演示。首先下载信安四大会2025年的会议论文数据：\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"dblp_sec_papers.json\"):\n",
    "    with requests.Session() as sess:\n",
    "        url = \"https://dblp.org/search/publ/api\"\n",
    "        params = {\"q\": \"security\", \"format\": \"json\"}\n",
    "        tocs = {\n",
    "            \"ndss\": \"toc:db/conf/ndss/ndss2025.bht:\",\n",
    "            \"sp\": \"toc:db/conf/sp/sp2025.bht:\",\n",
    "            \"ccs\": \"toc:db/conf/ccs/ccs2025.bht:\",\n",
    "            \"usenix\": \"toc:db/conf/uss/uss2025.bht:\",\n",
    "        }\n",
    "        papers = []\n",
    "        for k, v in tocs.items():\n",
    "            response = sess.get(url, params={\"q\": v, \"h\": 1000, \"format\": \"json\"})\n",
    "            data = response.json()\n",
    "            data = data[\"result\"][\"hits\"][\"hit\"]\n",
    "            papers.extend(data)\n",
    "        with open(f\"dblp_sec_papers.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "else:\n",
    "    with open(f\"dblp_sec_papers.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        papers = json.load(f)\n",
    "papers = [x[\"info\"] for x in papers]\n",
    "titles = [f\"[{x['venue']} {x['year']}] {x['title']}\" for x in papers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90abf541",
   "metadata": {},
   "source": [
    "在进行下一步之前，需要对环境进行一些配置，\n",
    "创建一个`.env`文件，并添加以下内容：\n",
    "\n",
    "-   示例 2：Siliconflow\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=your_siliconflow_api_key\n",
    "OPENAI_BASE_URL=https://api.siliconflow.cn/v1\n",
    "MODEL_NAME=Qwen/Qwen2.5-72B-Instruct\n",
    "EMB_MODEL_NAME=BAAI/bge-m3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff07b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建并保存向量数据库\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "\n",
    "load_dotenv()\n",
    "EMB_MODEL_NAME = environ.get(\"EMB_MODEL_NAME\", \"text-embedding-3\")\n",
    "if \"db\" not in globals():\n",
    "    chunks = []  # siliconflow max(bs)=64\n",
    "    for i in range(0, len(titles), 64):\n",
    "        chunk = titles[i : i + 64]\n",
    "        chunks.append(chunk)\n",
    "    for chunk in chunks:\n",
    "        if \"db\" not in globals():\n",
    "            db = FAISS.from_texts(chunk, OpenAIEmbeddings(model=EMB_MODEL_NAME))\n",
    "        else:\n",
    "            db.add_texts(chunk)\n",
    "db.save_local(\"faiss_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0352eb4d",
   "metadata": {},
   "source": [
    "## 方案0： 一切奇迹的始发点——传统工具调用\n",
    "\n",
    "在开始之前，先看一下传统的工具调用大概长啥样，有怎样的优缺点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ba0df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: llm安全\n",
      "Searching for keyword: llm安全\n",
      "kw='llm安全' appended.\n",
      "我发现了一些会议论文，但是这些论文似乎并没有直接涉及LLM（大型语言模型）的安全问题。例如，有很多关于隐私保护、恶意软件检测、数据泄露等主题的研究，但没有直接提到LLM安全。然而，这并不意味着LLM安全不是一个重要的研究领域。以下是一些可能相关的论文，尽管它们并不是直接针对LLM安全的：\n",
      "\n",
      "1. **隐私保护数据指纹技术的安全性保证**：[USENIX Security Symposium 2025] *Assuring Certified Database Utility in Privacy-Preserving Database Fingerprinting*。虽然主要关注数据库指纹技术，但隐私保护技术和LLM安全性可能有交集，特别是在处理大量个人数据时。\n",
      "\n",
      "2. **垂直隐私保护机器学习中的高效安全数据对齐框架**：[USENIX Security Symposium 2025] *Suda: An Efficient and Secure Unbalanced Data Alignment Framework for Vertical Privacy-Preserving Machine Learning*。虽然主要讨论的是数据对齐框架，但高效且安全的数据处理技术对于LLM的训练和应用安全同样重要。\n",
      "\n",
      "3. **教学数据科学学生通过启发式方法设计隐私方案**：[SP 2025] *Teaching Data Science Students to Sketch Privacy Designs Through Heuristics*。尽管是教育相关论文，但其中提到的隐私设计原则同样适用于LLM安全的设计。\n",
      "\n",
      "4. **安全感知的多代理信任估计器进行传感器融合**：[CCS 2025] *Security-Aware Sensor Fusion with MATE: the Multi-Agent Trust Estimator*。虽然关注的是传感器融合中的信任评估，但多代理系统和信任管理的概念在LLM应用场景中也非常相关，尤其是涉及到多个模型或数据源时。\n",
      "\n",
      "5. **图像变换的大规模验证**：[SP 2025] *VerITAS: Verifying Image Transformations at Scale*。虽然主要讨论的是图像处理的安全性，但大规模数据处理和验证的方法论对于LLM安全同样有价值。\n",
      "\n",
      "尽管上述论文没有直接讨论LLM安全，但它们涉及的技术和方法论可能对理解和解决LLM安全问题有所帮助。如果你有具体的LLM安全问题或者研究方向，可以进一步细化查询，以免漏掉可能相关的研究成果。\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import re\n",
    "from os import environ\n",
    "\n",
    "import dotenv\n",
    "import tenacity\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "from openai.types import *\n",
    "from openai.types.chat import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = environ.get(\"MODEL_NAME\", \"gpt-5.1\")\n",
    "EMB_MODEL_NAME = environ.get(\"EMB_MODEL_NAME\", \"text-embedding-3\")\n",
    "\n",
    "\n",
    "def raw_toolcall():\n",
    "    client = OpenAI()\n",
    "    db = FAISS.load_local(\n",
    "        \"faiss_db\",\n",
    "        OpenAIEmbeddings(model=EMB_MODEL_NAME),\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "    tools_def = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"query_paperdb\",\n",
    "                \"description\": \"accept keyword and return related information\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"kw\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The keyword to query the database\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"kw\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    def real_ask(question: str):\n",
    "        from openai.types.responses.response_input_param import Message\n",
    "\n",
    "        input_msgs: list[Message] = [\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are a helpful research assistant. When given a question, you must first decide if you need to query the database to get relevant information. If so, use the tool 'query_paperdb' with appropriate keywords extracted from the question. After getting the information, provide a comprehensive answer based on both the retrieved information and your own knowledge.\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            },\n",
    "        ]\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            tools=tools_def,\n",
    "            messages=input_msgs,\n",
    "            # tool_choice=\"required\",\n",
    "        )\n",
    "        input_msgs.append(resp.choices[0].message)\n",
    "        for toolcall in resp.choices[0].message.tool_calls:\n",
    "            if toolcall.type != \"function\":\n",
    "                continue\n",
    "            if toolcall.function.name == \"query_paperdb\":\n",
    "                kw = json.loads(toolcall.function.arguments)[\"kw\"]\n",
    "                print(f\"Keyword: {kw}\")\n",
    "                docs = []\n",
    "                for skw in kw.split():\n",
    "                    if not (skw := skw.strip()):\n",
    "                        continue\n",
    "                    print(f\"Searching for keyword: {skw}\")\n",
    "                    docs.extend(db.similarity_search(skw, k=10))\n",
    "                rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "                input_msgs.append(\n",
    "                    {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": toolcall.id,\n",
    "                        \"content\": str(rag_result),\n",
    "                    }\n",
    "                )\n",
    "                print(f\"{kw=} appended.\")\n",
    "        if input_msgs[-1][\"role\"] == \"tool\":\n",
    "            resp = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=input_msgs,\n",
    "                # tools=tools_def,\n",
    "                stream=True,\n",
    "            )\n",
    "            for chunk in resp:\n",
    "                print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "            print()\n",
    "        else:\n",
    "            print(resp.choices[0].message.content)\n",
    "\n",
    "    while True:\n",
    "        inp = input(\"=> \")\n",
    "        if not inp.strip():\n",
    "            break\n",
    "        real_ask(inp)\n",
    "\n",
    "\n",
    "raw_toolcall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0f2b1",
   "metadata": {},
   "source": [
    "### 传统工具调用的优缺点\n",
    "\n",
    "- 优点：直接用模型原生的 function/tool 调用协议，链路短、开销低，JSON Schema 参数校验清晰。\n",
    "- 优点：可以精确控制何时调用工具、使用 `tool_choice` 等参数强制执行，消息格式透明、便于调试和流式输出。\n",
    "- 优点：依赖少，不绑框架，易于插入到现有服务或与其他编排层组合。\n",
    "- 缺点：需要手写对话状态管理、工具输入输出拼接，容易出错且样板代码多。\n",
    "- 缺点：缺少自动规划/多步推理、重试、fallback 等封装能力，复杂流程要自行实现。\n",
    "- 缺点：与特定模型/协议耦合，换提供方或多模型时需适配；安全性与数据清洗（如反序列化、去重）也要自管。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888af19",
   "metadata": {},
   "source": [
    "## 方案1： SmolAgent::CodeAgent\n",
    "\n",
    "SmolAgent::CodeAgent 拥有两种提示模板，使用`use_structured_outputs_internally`参数进行控制。\n",
    "- 核心循环：两条线路都遵循多步推理，但输出格式不同。\n",
    "  - 标准版（`code_agent.yaml`，`use_structured_outputs_internally=False`）：每步输出 Thought→Code→Observation，代码必须包裹在自定义 `{{code_block_opening_tag}}`/`{{code_block_closing_tag}}` 中；中间结果用 `print` 进入 Observation，最终用 `final_answer` 收束。\n",
    "  - 结构化版（`structured_code_agent.yaml`，`use_structured_outputs_internally=True`）：每步输出固定 JSON `{ \"thought\": \"...\", \"code\": \"...\" }`，默认不需要自定义 code_block 标签；解析稳定、便于日志/回放。\n",
    "- 规划 scaffold：两者都要求先做 facts survey + high-level plan（initial_plan / update_plan），但标准版在文本里更强调「分步打印、避免链式依赖」。\n",
    "- 工具调用与链式策略：\n",
    "  - 标准版明确区分“有 JSON schema 的工具可以链式调用，非结构化工具应先 `print` 再下一步用”，并警示不要重做相同参数的调用、不要用工具名做变量名。\n",
    "  - 结构化版主要提供最小约束（定义变量再用、参数名显式），输出以 JSON 承载 Thought 和 Code，便于上层程序直接消费。\n",
    "- 执行与可读性：\n",
    "  - 标准版输出包含 Thought/Code/Observation 叙事，适合人工旁观调试、流式展示和教学场景。\n",
    "  - 结构化版输出紧凑、机器友好，适合日志解析、监控、对接编排器或二次路由。\n",
    "- 选择建议：\n",
    "  - 需要确定性结构、便于程序解析/回放/审计时，用 `use_structured_outputs_internally=True`（结构化版）。\n",
    "  - 需要人类可读的逐步对话、希望看到 code_block 包裹和 Observation 明细，或想依赖模板中的链式提示时，用 `use_structured_outputs_internally=False`（标准版）。\n",
    "- 常见踩坑提示：\n",
    "  - 标准版务必保持自定义 code_block 标签，否则解析失败；非结构化工具调用不要在同一块紧接依赖下一工具输出。\n",
    "  - 结构化版的 JSON 输出中请将可执行代码写在 `code` 字段，仍需显式 `final_answer(...)` 收口；确保不要把工具名当变量名。\n",
    "- 性能与上下文：标准版提示体积更大，可能略增 token 开销；结构化版更紧凑，节省上下文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d330b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You are a helpful research assistant.</span>                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">When given a question, you must query the database to get relevant information.</span>                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Use the tools with appropriate arguments derived from the question.</span>                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">After getting the information, provide a comprehensive answer based on both the retrieved information.</span>          <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Output the final answer in markdown wrapped in final_answer().</span>                                                  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">查找llm安全相关论文</span>                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIModel - Qwen/Qwen2.5-72B-Instruct ───────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou are a helpful research assistant.\u001b[0m                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWhen given a question, you must query the database to get relevant information.\u001b[0m                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mUse the tools with appropriate arguments derived from the question.\u001b[0m                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mAfter getting the information, provide a comprehensive answer based on both the retrieved information.\u001b[0m          \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mOutput the final answer in markdown wrapped in final_answer().\u001b[0m                                                  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m查找llm安全相关论文\u001b[0m                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIModel - Qwen/Qwen2.5-72B-Instruct \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db67f10e24aa4035b8eb1093d8b4414b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> query_paperdb(kw</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"LLM安全\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(papers)</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery_paperdb\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkw\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mLLM安全\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for keyword: LLM安全\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[CCS 2025] Deep Dive into In-app Browsers: Uncovering Hidden Pitfalls in Certificate Validation.\n",
       "[CCS 2025] Empirical Security Analysis of Software-based Fault Isolation through Controlled Fault Injection.\n",
       "[CCS 2025] Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.\n",
       "[NDSS 2025] DShield: Defending against Backdoor Attacks on Graph Neural Networks via Discrepancy Learning.\n",
       "[CCS 2025] ACM CCS Young Scholars Development Program.\n",
       "[USENIX Security Symposium 2025] How Transparent is Usable Privacy and Security Research? A Meta-Study on Current \n",
       "Research Transparency Practices.\n",
       "[CCS 2025] Updatable aPAKE: Security Against Bulk Precomputation Attacks.\n",
       "[NDSS 2025] Passive Inference Attacks on Split Learning via Adversarial Regularization.\n",
       "[CCS 2025] BASTAG: Byte-level Access Control on Shared Memory using ARM Memory Tagging Extension.\n",
       "[CCS 2025] BFId: Identity Inference Attacks Utilizing Beamforming Feedback Information.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[CCS 2025] Deep Dive into In-app Browsers: Uncovering Hidden Pitfalls in Certificate Validation.\n",
       "[CCS 2025] Empirical Security Analysis of Software-based Fault Isolation through Controlled Fault Injection.\n",
       "[CCS 2025] Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.\n",
       "[NDSS 2025] DShield: Defending against Backdoor Attacks on Graph Neural Networks via Discrepancy Learning.\n",
       "[CCS 2025] ACM CCS Young Scholars Development Program.\n",
       "[USENIX Security Symposium 2025] How Transparent is Usable Privacy and Security Research? A Meta-Study on Current \n",
       "Research Transparency Practices.\n",
       "[CCS 2025] Updatable aPAKE: Security Against Bulk Precomputation Attacks.\n",
       "[NDSS 2025] Passive Inference Attacks on Split Learning via Adversarial Regularization.\n",
       "[CCS 2025] BASTAG: Byte-level Access Control on Shared Memory using ARM Memory Tagging Extension.\n",
       "[CCS 2025] BFId: Identity Inference Attacks Utilizing Beamforming Feedback Information.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 2.38 seconds| Input tokens: 126,850 | Output tokens: 1,764]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 2.38 seconds| Input tokens: 126,850 | Output tokens: 1,764]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15654d3a6c504bf68750927aa91fd9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">f\"以下论文与LLM安全相关：</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">\\n</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **{</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">][</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'title'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}**，发表于 {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">][</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'conference'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">         </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mf\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m以下论文与LLM安全相关：\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m\\n\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtitle\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m**，发表于 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mconference\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m         \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Code execution failed at line 'final_answer(f\"以下论文与LLM安全相关：\\n- **{papers[2\\]['title'\\]}**，发表于 </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">{papers[2\\]['conference'\\]}\")' due to: InterpreterError: Could not index C with 'title': TypeError: string indices </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">must be integers, not 'str'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mCode execution failed at line 'final_answer(f\"以下论文与LLM安全相关：\\n- **{papers[2\\]['title'\\]}**，发表于 \u001b[0m\n",
       "\u001b[1;31m{papers[2\\]['conference'\\]}\")' due to: InterpreterError: Could not index C with 'title': TypeError: string indices \u001b[0m\n",
       "\u001b[1;31mmust be integers, not 'str'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 5.04 seconds| Input tokens: 436,852 | Output tokens: 9,142]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 5.04 seconds| Input tokens: 436,852 | Output tokens: 9,142]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2915f7cc5f4c30b000e91ed1d411b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(papers)</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[CCS 2025] Deep Dive into In-app Browsers: Uncovering Hidden Pitfalls in Certificate Validation.\n",
       "[CCS 2025] Empirical Security Analysis of Software-based Fault Isolation through Controlled Fault Injection.\n",
       "[CCS 2025] Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.\n",
       "[NDSS 2025] DShield: Defending against Backdoor Attacks on Graph Neural Networks via Discrepancy Learning.\n",
       "[CCS 2025] ACM CCS Young Scholars Development Program.\n",
       "[USENIX Security Symposium 2025] How Transparent is Usable Privacy and Security Research? A Meta-Study on Current \n",
       "Research Transparency Practices.\n",
       "[CCS 2025] Updatable aPAKE: Security Against Bulk Precomputation Attacks.\n",
       "[NDSS 2025] Passive Inference Attacks on Split Learning via Adversarial Regularization.\n",
       "[CCS 2025] BASTAG: Byte-level Access Control on Shared Memory using ARM Memory Tagging Extension.\n",
       "[CCS 2025] BFId: Identity Inference Attacks Utilizing Beamforming Feedback Information.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[CCS 2025] Deep Dive into In-app Browsers: Uncovering Hidden Pitfalls in Certificate Validation.\n",
       "[CCS 2025] Empirical Security Analysis of Software-based Fault Isolation through Controlled Fault Injection.\n",
       "[CCS 2025] Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.\n",
       "[NDSS 2025] DShield: Defending against Backdoor Attacks on Graph Neural Networks via Discrepancy Learning.\n",
       "[CCS 2025] ACM CCS Young Scholars Development Program.\n",
       "[USENIX Security Symposium 2025] How Transparent is Usable Privacy and Security Research? A Meta-Study on Current \n",
       "Research Transparency Practices.\n",
       "[CCS 2025] Updatable aPAKE: Security Against Bulk Precomputation Attacks.\n",
       "[NDSS 2025] Passive Inference Attacks on Split Learning via Adversarial Regularization.\n",
       "[CCS 2025] BASTAG: Byte-level Access Control on Shared Memory using ARM Memory Tagging Extension.\n",
       "[CCS 2025] BFId: Identity Inference Attacks Utilizing Beamforming Feedback Information.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 5.77 seconds| Input tokens: 673,402 | Output tokens: 12,702]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 5.77 seconds| Input tokens: 673,402 | Output tokens: 12,702]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 4</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 4\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c086da8004648ea83fcd1e733bad052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Split the papers into a list of strings</span><span style=\"background-color: #272822\">                                                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">paper_list </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> papers</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">split(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">\\n</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Find the relevant paper</span><span style=\"background-color: #272822\">                                                                                      </span>  \n",
       "  <span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">for</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> paper </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> paper_list:</span><span style=\"background-color: #272822\">                                                                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">if</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> paper:</span><span style=\"background-color: #272822\">    </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        relevant_paper </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> paper</span><span style=\"background-color: #272822\">                                                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">break</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Extract the conference information</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">conference </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> relevant_paper</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">split(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"]\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">strip(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Extract the title</span><span style=\"background-color: #272822\">                                                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">title </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> relevant_paper</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">split(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"]\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">strip()</span><span style=\"background-color: #272822\">                                                                   </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Provide the final answer</span><span style=\"background-color: #272822\">                                                                                     </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">f\"以下论文与LLM安全相关：</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">\\n</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **{</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">title</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}**，发表于 {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">conference</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                   </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Split the papers into a list of strings\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mpaper_list\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msplit\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m\\n\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Find the relevant paper\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m  \n",
       "  \u001b[38;2;102;217;239;48;2;39;40;34mfor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpaper\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpaper_list\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mGLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpaper\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m    \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrelevant_paper\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpaper\u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mbreak\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Extract the conference information\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mconference\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrelevant_paper\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msplit\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstrip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Extract the title\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mtitle\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrelevant_paper\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msplit\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstrip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                   \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Provide the final answer\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mf\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m以下论文与LLM安全相关：\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m\\n\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtitle\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m**，发表于 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mconference\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: 以下论文与LLM安全相关：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.**，发表于 CCS</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">2025</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: 以下论文与LLM安全相关：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- **Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.**，发表于 CCS\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m2025\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 4: Duration 8.61 seconds| Input tokens: 1,310,794 | Output tokens: 31,809]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 4: Duration 8.61 seconds| Input tokens: 1,310,794 | Output tokens: 31,809]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from smolagents import CodeAgent, OpenAIServerModel, tool\n",
    "from os import environ\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_NAME = environ.get(\"MODEL_NAME\", \"gpt-5.1\")\n",
    "EMB_MODEL_NAME = environ.get(\"EMB_MODEL_NAME\", \"text-embedding-3\")\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    \"faiss_db\",\n",
    "    OpenAIEmbeddings(model=EMB_MODEL_NAME),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "You are a helpful research assistant.\n",
    "When given a question, you must query the database to get relevant information.\n",
    "Use the tools with appropriate arguments derived from the question.\n",
    "After getting the information, provide a comprehensive answer based on both the retrieved information.\n",
    "Output the final answer in markdown wrapped in final_answer().\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_paperdb(kw: str) -> str:\n",
    "    \"\"\"\n",
    "    Accept keywords and return related paper titles, multiple keywords should be separated by '|'.\n",
    "    This tool should be called before output any realworld-related information.\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword to query the database\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for skw in kw.split(\"|\"):\n",
    "        if not (skw := skw.strip()):\n",
    "            continue\n",
    "        print(f\"Searching for keyword: {skw}\")\n",
    "        docs.extend(db.similarity_search(skw, k=10))\n",
    "    rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return rag_result\n",
    "\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model=OpenAIServerModel(MODEL_NAME),\n",
    "    tools=[query_paperdb],\n",
    "    stream_outputs=True,\n",
    "    # use_structured_outputs_internally=True, # True for structured_code_agent.yaml, False for code_agent.yaml\n",
    ")\n",
    "\n",
    "# from Gradio_UI import GradioUI\n",
    "\n",
    "# GradioUI(agent).launch()\n",
    "\n",
    "_ = agent.run(f\"{sys_prompt}\\n\\n{input(\"=> \")}\", return_full_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5978dc",
   "metadata": {},
   "source": [
    "## 方案2： LangGraph\n",
    "\n",
    "以下代码块用 LangGraph 重新实现「检索→工具调用→回答」的代理流程，强调显式状态机与可视化路由的优势：\n",
    "\n",
    "\n",
    "\n",
    "- 基础资源：启动时加载 `.env`，用 `FAISS.load_local` + `OpenAIEmbeddings` 复用前面构建的向量库，确保跨会话复现检索结果。\n",
    "\n",
    "- 系统提示：`sys_prompt` 要求回答前必须调用检索工具，并用 `final_answer(...)` 收口；保持与前两种方案一致，便于对比 token 与行为。\n",
    "\n",
    "- 工具实现：`@tool` 装饰的 `query_paperdb` 按 `|` 分割多关键词，每个关键词检索 top-10，stdout 打印检索日志，返回拼接文本作为 RAG 证据。\n",
    "\n",
    "- 模型与绑定：`ChatOpenAI(model=\"gpt-5.1\", verbose=True)` 绑定工具得到 `chat_with_tools`，LangGraph 自动根据模型给出的 `tool_calls` 决定是否进入工具节点。\n",
    "\n",
    "- 状态与路由：`AgentState` 仅维护 `messages`（用 `add_messages` 合并），`StateGraph` 定义两个节点：\n",
    "  - `assistant`：调用大模型，可能产出工具调用或直接回答。\n",
    "  - `tools`：`ToolNode` 执行 `query_paperdb` 并把结果写回消息。\n",
    " 通过 `tools_condition` 条件边在两节点间循环，直到模型不再请求工具。\n",
    "\n",
    "- 编译与运行：`builder.compile()` 得到 `agent`，随后用 `SystemMessage+HumanMessage` 作为初始消息调用 `agent.invoke`。执行结束后按顺序打印每段回复，便于观察模型与工具交替的对话片段。\n",
    "\n",
    "- 适用场景：当需要显式控制多轮工具路由、插入额外节点（如过滤、重排序、裁剪上下文）或做流程可视化/监控时，LangGraph 方案更易扩展；相较裸工具调用（方案0）和 SmolAgent（方案1），它在可编排性与可观测性上更强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a9a193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for keyword: llm safety\n",
      "Searching for keyword: large language model security\n",
      "Searching for keyword: LLM security\n",
      "Searching for keyword: LLM safety\n",
      "Part 0: \n",
      "You are a helpful research assistant.\n",
      "When given a question, you must query the database to get relevant information.\n",
      "Use the tools with appropriate arguments derived from the question.\n",
      "After getting the information, provide a comprehensive answer based on both the retrieved information.\n",
      "Output the final answer in markdown wrapped in final_answer().\n",
      "\n",
      "\n",
      "Part 1: \n",
      "查找llm安全相关论文\n",
      "\n",
      "\n",
      "Part 2: \n",
      "\n",
      "\n",
      "\n",
      "Part 3: \n",
      "[CCS 2025] Don&apos;t Panic! Finding Bugs Hidden Behind Rust Runtime Safety Checks.\n",
      "[SP 2025] Half Spectre, Full Exploit: Hardening Rowhammer Attacks with Half-Spectre Gadgets.\n",
      "[USENIX Security Symposium 2025] Secure Caches for Compartmentalized Software.\n",
      "[USENIX Security Symposium 2025] Precise and Effective Gadget Chain Mining through Deserialization Guided Call Graph Construction.\n",
      "[USENIX Security Symposium 2025] A Framework for Designing Provably Secure Steganography.\n",
      "[USENIX Security Symposium 2025] Characterizing and Detecting Propaganda-Spreading Accounts on Telegram.\n",
      "[USENIX Security Symposium 2025] GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors.\n",
      "[USENIX Security Symposium 2025] Assuring Certified Database Utility in Privacy-Preserving Database Fingerprinting.\n",
      "[SP 2025] TreeKEM: A Modular Machine-Checked Symbolic Security Analysis of Group Key Agreement in Messaging Layer Security.\n",
      "[SP 2025] Study Club, Labor Union or Start-Up? Characterizing Teams and Collaboration in the Bug Bounty Ecosystem.\n",
      "[SP 2025] Mixnets on a Tightrope: Quantifying the Leakage of Mix Networks Using a Provably Optimal Heuristic Adversary.\n",
      "[SP 2025] Verifiable Boosted Tree Ensembles.\n",
      "[CCS 2025] Poster: The Rocky Road Towards RPKI Algorithm Agility.\n",
      "[SP 2025] Sniffing Location Privacy of Video Conference Users Using Free Audio Channels.\n",
      "[CCS 2025] End-to-End Encrypted Git Services.\n",
      "[SP 2025] Spoofing Eavesdroppers with Audio Misinformation.\n",
      "[CCS 2025] RebirthDay Attack: Reviving DNS Cache Poisoning with the Birthday Paradox.\n",
      "[SP 2025] SoK: Decoding the Enigma of Encrypted Network Traffic Classifiers.\n",
      "[CCS 2025] CuKEM: A Concise and Unified Hybrid Key Encapsulation Mechanism.\n",
      "[SP 2025] Transport Layer Obscurity: Circumventing SNI Censorship on the TLS-Layer.\n",
      "[NDSS 2025] PowerRadio: Manipulate Sensor Measurement via Power GND Radiation.\n",
      "[NDSS 2025] YuraScanner: Leveraging LLMs for Task-driven Web App Scanning.\n",
      "[CCS 2025] BFId: Identity Inference Attacks Utilizing Beamforming Feedback Information.\n",
      "[CCS 2025] ACM CCS Young Scholars Development Program.\n",
      "[CCS 2025] TensorShield: Safeguarding On-Device Inference by Shielding Critical DNN Tensors with TEE.\n",
      "[CCS 2025] Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.\n",
      "[CCS 2025] WireTap: Breaking Server SGX via DRAM Bus Interposition.\n",
      "[CCS 2025] Safeguarding Graph Neural Networks against Topology Inference Attacks.\n",
      "[CCS 2025] Membership Inference Attacks as Privacy Tools: Reliability, Disparity and Ensemble.\n",
      "[CCS 2025] The 20th Workshop on Programming Languages and Analysis for Security (PLAS 2025).\n",
      "[USENIX Security Symposium 2025] A Framework for Designing Provably Secure Steganography.\n",
      "[CCS 2025] LZKSA: Lattice-Based Special Zero-Knowledge Proofs for Secure Aggregation&apos;s Input Verification.\n",
      "[USENIX Security Symposium 2025] Phantom: Privacy-Preserving Deep Neural Network Model Obfuscation in Heterogeneous TEE and GPU System.\n",
      "[CCS 2025] Augmenting Search-based Program Synthesis with Local Inference Rules to Improve Black-box Deobfuscation.\n",
      "[USENIX Security Symposium 2025] Private Set Intersection and other Set Operations in the Third Party Setting.\n",
      "[SP 2025] MicroNova: Folding-Based Arguments with Efficient (On-Chain) Verification.\n",
      "[USENIX Security Symposium 2025] Precise and Effective Gadget Chain Mining through Deserialization Guided Call Graph Construction.\n",
      "[CCS 2025] Head(er)s Up! Detecting Security Header Inconsistencies in Browsers.\n",
      "[USENIX Security Symposium 2025] Digital Security Perceptions and Practices Around the World: A WEIRD versus Non-WEIRD Comparison.\n",
      "[CCS 2025] BOLT: Bandwidth-Optimized Lightning-Fast Oblivious Map powered by Secure HBM Accelerators.\n",
      "\n",
      "\n",
      "Part 4: \n",
      "从检索到的论文信息来看，以下几篇论文与大型语言模型（LLM）安全相关：\n",
      "\n",
      "- **[YuraScanner: Leveraging LLMs for Task-driven Web App Scanning. NDSS 2025]**：本文探讨了利用LLM进行任务驱动的Web应用程序扫描，以提高安全测试的效率和准确性。\n",
      "- **[GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering. CCS 2025 (Poster)]**：该研究通过指令调整LLM和聚类技术预测日志异常类型，以实现自进化的日志异常检测。\n",
      "- **[TensorShield: Safeguarding On-Device Inference by Shielding Critical DNN Tensors with TEE. CCS 2025]**：本文提出了一种基于TEE（可信执行环境）保护设备上关键DNN张量的方法，以增强LLM的安全性。\n",
      "- **[Phantom: Privacy-Preserving Deep Neural Network Model Obfuscation in Heterogeneous TEE and GPU System. USENIX Security Symposium 2025]**：该研究探讨了如何在异构TEE和GPU系统中实现深度神经网络模型的隐私保护和混淆，以增强LLM的安全性。\n",
      "- **[Safeguarding Graph Neural Networks against Topology Inference Attacks. CCS 2025]**：本文研究了如何保护图神经网络免受拓扑推断攻击，这与LLM的安全性密切相关。\n",
      "- **[Membership Inference Attacks as Privacy Tools: Reliability, Disparity and Ensemble. CCS 2025]**：该研究探讨了成员推断攻击作为隐私保护工具的可靠性和差异性，这与LLM的隐私保护机制密切相关。\n",
      "\n",
      "这些论文涵盖了LLM安全的多个方面，包括恶意软件检测、日志分析、隐私保护、模型安全和对抗性攻击等。希望这些信息对您的研究有所帮助。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.tools import tool\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_NAME = environ.get(\"MODEL_NAME\", \"gpt-5.1\")\n",
    "EMB_MODEL_NAME = os.environ.get(\"EMB_MODEL_NAME\", \"text-embedding-3\")\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    \"faiss_db\",\n",
    "    OpenAIEmbeddings(model=EMB_MODEL_NAME),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "You are a helpful research assistant.\n",
    "When given a question, you must query the database to get relevant information.\n",
    "Use the tools with appropriate arguments derived from the question.\n",
    "After getting the information, provide a comprehensive answer based on both the retrieved information.\n",
    "Output the final answer in markdown wrapped in final_answer().\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_paperdb(kw: str) -> str:\n",
    "    \"\"\"\n",
    "    Accept keywords and return related paper titles, multiple keywords should be separated by '|'.\n",
    "    This tool should be called before output any realworld-related information.\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword to query the database\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for skw in kw.split(\"|\"):\n",
    "        if not (skw := skw.strip()):\n",
    "            continue\n",
    "        print(f\"Searching for keyword: {skw}\")\n",
    "        docs.extend(db.similarity_search(skw, k=10))\n",
    "    rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return rag_result\n",
    "\n",
    "\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import AIMessage, AnyMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "chat = ChatOpenAI(model=MODEL_NAME, verbose=True)\n",
    "chat_with_tools = chat.bind_tools([query_paperdb])\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    return {\n",
    "        \"messages\": [chat_with_tools.invoke(state[\"messages\"])],\n",
    "    }\n",
    "\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([query_paperdb]))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "agent = builder.compile()\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=sys_prompt),\n",
    "    HumanMessage(content=input(\"=> \")),\n",
    "]\n",
    "\n",
    "response = agent.invoke({\"messages\": messages})\n",
    "\n",
    "for idx, part in enumerate(response[\"messages\"]):\n",
    "    print(f\"Part {idx}: \\n{part.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562bfc9c",
   "metadata": {},
   "source": [
    "## 方案3： CodeAgent + MCP (Model Context Protocol)\n",
    "\n",
    "这一节展示如何通过 MCP 将外部工具集合挂载给 SmolAgent 的 CodeAgent，并保持与前面方案一致的“先检索后回答”规范。使用前请先在本目录启动 `mcp-1.py` 以提供本地 MCP 服务器。\n",
    "\n",
    "\n",
    "\n",
    "- 启动服务：在终端运行 `python mcp-1.py`，保持进程存活，默认监听 `http://127.0.0.1:8000/mcp`。\n",
    "\n",
    "- 工具获取：`ToolCollection.from_mcp` 以 streamable-http 方式连接服务器，`trust_remote_code=True` 允许加载远端工具实现，`structured_output=False` 让工具返回原始文本。\n",
    "\n",
    "- 代理配置：创建 `CodeAgent(model=OpenAIServerModel(\"gpt-5.1\"), tools=[*tool_collection.tools], stream_outputs=True, use_structured_outputs_internally=True)`，沿用 `sys_prompt` 强制先调用工具，再用 `final_answer(...)` 收口。\n",
    "\n",
    "- 运行流程：读取用户输入后直接 `agent.run`，中间的工具调用与结果交由 MCP 服务提供，实现与本地代码解耦、便于统一暴露多工具。\n",
    "\n",
    "- 适用场景：需要集中托管工具、复用跨项目/多语言工具链，或将工具部署为独立服务时，MCP 能作为标准化桥梁，保持模型侧最小改动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af638e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You are a helpful research assistant.</span>                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">When given a question, you must query the database to get relevant information.</span>                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Use the tools with appropriate arguments derived from the question.</span>                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">After getting the information, provide a comprehensive answer based on both the retrieved information.</span>          <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">* Output the final answer in markdown wrapped in final_answer().</span>                                                <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">查找llm安全相关论文</span>                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIModel - Qwen/Qwen2.5-72B-Instruct ───────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou are a helpful research assistant.\u001b[0m                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWhen given a question, you must query the database to get relevant information.\u001b[0m                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mUse the tools with appropriate arguments derived from the question.\u001b[0m                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mAfter getting the information, provide a comprehensive answer based on both the retrieved information.\u001b[0m          \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m* Output the final answer in markdown wrapped in final_answer().\u001b[0m                                                \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m查找llm安全相关论文\u001b[0m                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIModel - Qwen/Qwen2.5-72B-Instruct \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f999a816d214f6b8c6fb5ede25415e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> query_paperdb(kw</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'LLM安全'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(papers)</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery_paperdb\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkw\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mLLM安全\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[CCS 2025] Deep Dive into In-app Browsers: Uncovering Hidden Pitfalls in Certificate Validation.\n",
       "[CCS 2025] Empirical Security Analysis of Software-based Fault Isolation through Controlled Fault Injection.\n",
       "[CCS 2025] Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.\n",
       "[NDSS 2025] DShield: Defending against Backdoor Attacks on Graph Neural Networks via Discrepancy Learning.\n",
       "[CCS 2025] ACM CCS Young Scholars Development Program.\n",
       "[USENIX Security Symposium 2025] How Transparent is Usable Privacy and Security Research? A Meta-Study on Current \n",
       "Research Transparency Practices.\n",
       "[CCS 2025] Updatable aPAKE: Security Against Bulk Precomputation Attacks.\n",
       "[NDSS 2025] Passive Inference Attacks on Split Learning via Adversarial Regularization.\n",
       "[CCS 2025] BASTAG: Byte-level Access Control on Shared Memory using ARM Memory Tagging Extension.\n",
       "[CCS 2025] BFId: Identity Inference Attacks Utilizing Beamforming Feedback Information.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[CCS 2025] Deep Dive into In-app Browsers: Uncovering Hidden Pitfalls in Certificate Validation.\n",
       "[CCS 2025] Empirical Security Analysis of Software-based Fault Isolation through Controlled Fault Injection.\n",
       "[CCS 2025] Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned LLM and Clustering.\n",
       "[NDSS 2025] DShield: Defending against Backdoor Attacks on Graph Neural Networks via Discrepancy Learning.\n",
       "[CCS 2025] ACM CCS Young Scholars Development Program.\n",
       "[USENIX Security Symposium 2025] How Transparent is Usable Privacy and Security Research? A Meta-Study on Current \n",
       "Research Transparency Practices.\n",
       "[CCS 2025] Updatable aPAKE: Security Against Bulk Precomputation Attacks.\n",
       "[NDSS 2025] Passive Inference Attacks on Split Learning via Adversarial Regularization.\n",
       "[CCS 2025] BASTAG: Byte-level Access Control on Shared Memory using ARM Memory Tagging Extension.\n",
       "[CCS 2025] BFId: Identity Inference Attacks Utilizing Beamforming Feedback Information.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 3.45 seconds| Input tokens: 89,654 | Output tokens: 1,032]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 3.45 seconds| Input tokens: 89,654 | Output tokens: 1,032]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970b9861c6a24c4ab6e735f74f4f35ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> query_paperdb(kw</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'large language model|LLM 安全'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                     </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(papers)</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery_paperdb\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkw\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mlarge language model|LLM 安全\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[SP 2025] Verifiable Secret Sharing Simplified.\n",
       "[SP 2025] PGUS: Pretty Good User Security for Thick MVNOs with a Novel Sanitizable Blind Signature.\n",
       "[NDSS 2025] Secure IP Address Allocation at Cloud Scale.\n",
       "[SP 2025] Verifiable Boosted Tree Ensembles.\n",
       "[CCS 2025] Optimal Mechanisms for Quantum Local Differential Privacy.\n",
       "[SP 2025] Sniffing Location Privacy of Video Conference Users Using Free Audio Channels.\n",
       "[CCS 2025] Poster: The Rocky Road Towards RPKI Algorithm Agility.\n",
       "[USENIX Security Symposium 2025] Current Affairs: A Security Measurement Study of CCS EV Charging Deployments.\n",
       "[USENIX Security Symposium 2025] Sound and Efficient Generation of Data-Oriented Exploits via Programming Language \n",
       "Synthesis.\n",
       "[CCS 2025] How to Design Secure Honey Vault Schemes.\n",
       "[CCS 2025] BLACKOUT: Data-Oblivious Computation with Blinded Capabilities.\n",
       "[CCS 2025] Fast Homomorphic Evaluation of LWR-based PRFs.\n",
       "[CCS 2025] Poster: The Rocky Road Towards RPKI Algorithm Agility.\n",
       "[CCS 2025] Intent-aware Fuzzing for Android Hardened Application.\n",
       "[CCS 2025] AgentSentinel: An End-to-End and Real-Time Security Defense Framework for Computer-Use Agents.\n",
       "[SP 2025] Mon CHERI: Mitigating Uninitialized Memory Access with Conditional Capabilities.\n",
       "[CCS 2025] Beyond Tag Collision: Cluster-based Memory Management for Tag-based Sanitizers.\n",
       "[CCS 2025] Training Robust Classifiers for Classifying Encrypted Traffic under Dynamic Network Conditions.\n",
       "[SP 2025] GPTracker: A Large-Scale Measurement of Misused GPTs.\n",
       "[CCS 2025] Fuzzing Processing Pipelines for Zero-Knowledge Circuits.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[SP 2025] Verifiable Secret Sharing Simplified.\n",
       "[SP 2025] PGUS: Pretty Good User Security for Thick MVNOs with a Novel Sanitizable Blind Signature.\n",
       "[NDSS 2025] Secure IP Address Allocation at Cloud Scale.\n",
       "[SP 2025] Verifiable Boosted Tree Ensembles.\n",
       "[CCS 2025] Optimal Mechanisms for Quantum Local Differential Privacy.\n",
       "[SP 2025] Sniffing Location Privacy of Video Conference Users Using Free Audio Channels.\n",
       "[CCS 2025] Poster: The Rocky Road Towards RPKI Algorithm Agility.\n",
       "[USENIX Security Symposium 2025] Current Affairs: A Security Measurement Study of CCS EV Charging Deployments.\n",
       "[USENIX Security Symposium 2025] Sound and Efficient Generation of Data-Oriented Exploits via Programming Language \n",
       "Synthesis.\n",
       "[CCS 2025] How to Design Secure Honey Vault Schemes.\n",
       "[CCS 2025] BLACKOUT: Data-Oblivious Computation with Blinded Capabilities.\n",
       "[CCS 2025] Fast Homomorphic Evaluation of LWR-based PRFs.\n",
       "[CCS 2025] Poster: The Rocky Road Towards RPKI Algorithm Agility.\n",
       "[CCS 2025] Intent-aware Fuzzing for Android Hardened Application.\n",
       "[CCS 2025] AgentSentinel: An End-to-End and Real-Time Security Defense Framework for Computer-Use Agents.\n",
       "[SP 2025] Mon CHERI: Mitigating Uninitialized Memory Access with Conditional Capabilities.\n",
       "[CCS 2025] Beyond Tag Collision: Cluster-based Memory Management for Tag-based Sanitizers.\n",
       "[CCS 2025] Training Robust Classifiers for Classifying Encrypted Traffic under Dynamic Network Conditions.\n",
       "[SP 2025] GPTracker: A Large-Scale Measurement of Misused GPTs.\n",
       "[CCS 2025] Fuzzing Processing Pipelines for Zero-Knowledge Circuits.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 5.33 seconds| Input tokens: 340,646 | Output tokens: 6,822]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 5.33 seconds| Input tokens: 340,646 | Output tokens: 6,822]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6622f82e5c4b6c871a6b92ccf035db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'''虽然查询结果中并未直接出现大量与LLM安全性相关的论文，但可以注意到以下一篇论文提到通过大规模测量</span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">分析GPT（一种LLM）的滥用情况，间接探讨了LLM的安全性问题：</span><span style=\"background-color: #272822\">                                                      </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **[SP 2025] GPTracker: A Large-Scale Measurement of Misused GPTs**</span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  这篇论文对GPT的大规模滥用情况进行了测量，为理解LLM在安全领域的潜在风险提供了重要 insights。'''</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">              </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'''\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m虽然查询结果中并未直接出现大量与LLM安全性相关的论文，但可以注意到以下一篇论文提到通过大规模测量\u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m分析GPT（一种LLM）的滥用情况，间接探讨了LLM的安全性问题：\u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- **[SP 2025] GPTracker: A Large-Scale Measurement of Misused GPTs**\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m  这篇论文对GPT的大规模滥用情况进行了测量，为理解LLM在安全领域的潜在风险提供了重要 insights。\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'''\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m              \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">虽然查询结果中并未直接出现大量与LLM安全性相关的论文，但可以注意到以下一篇论文提到通过大规模测量分析GPT（一种LLM）的</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">滥用情况，间接探讨了LLM的安全性问题：</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **[SP 2025] GPTracker: A Large-Scale Measurement of Misused GPTs**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  这篇论文对GPT的大规模滥用情况进行了测量，为理解LLM在安全领域的潜在风险提供了重要 insights。</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m虽然查询结果中并未直接出现大量与LLM安全性相关的论文，但可以注意到以下一篇论文提到通过大规模测量分析GPT（一种LLM）的\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m滥用情况，间接探讨了LLM的安全性问题：\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **[SP 2025] GPTracker: A Large-Scale Measurement of Misused GPTs**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  这篇论文对GPT的大规模滥用情况进行了测量，为理解LLM在安全领域的潜在风险提供了重要 insights。\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 10.10 seconds| Input tokens: 869,949 | Output tokens: 22,781]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 10.10 seconds| Input tokens: 869,949 | Output tokens: 22,781]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from smolagents import CodeAgent, OpenAIServerModel, ToolCollection\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_NAME = environ.get(\"MODEL_NAME\", \"gpt-5.1\")\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "You are a helpful research assistant.\n",
    "When given a question, you must query the database to get relevant information.\n",
    "Use the tools with appropriate arguments derived from the question.\n",
    "After getting the information, provide a comprehensive answer based on both the retrieved information.\n",
    "* Output the final answer in markdown wrapped in final_answer().\n",
    "\"\"\".strip()\n",
    "\n",
    "with ToolCollection.from_mcp(\n",
    "    {\"url\": \"http://127.0.0.1:8000/mcp\", \"transport\": \"streamable-http\"},\n",
    "    trust_remote_code=True,\n",
    "    structured_output=False,\n",
    ") as tool_collection:\n",
    "    agent = CodeAgent(\n",
    "        model=OpenAIServerModel(MODEL_NAME),\n",
    "        tools=[*tool_collection.tools],\n",
    "        stream_outputs=True,\n",
    "        use_structured_outputs_internally=True,\n",
    "    )\n",
    "\n",
    "    # from Gradio_UI import GradioUI\n",
    "\n",
    "    # GradioUI(agent).launch()\n",
    "\n",
    "    agent.run(f\"{sys_prompt}\\n\\n{input('=> ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98876349",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- 数据基座：从 dblp 拉取信安四大会 2025 TOC，用 `OpenAIEmbeddings` 构建并持久化 `FAISS` 向量库，后续各方案共享。\n",
    "\n",
    "- 方案0（原生 tool call）：直接用 OpenAI `responses.create` + JSON Schema 工具。链路最短、调试透明、可强制 `tool_choice`；但对话状态管理、重试、去重、输出都要手写。\n",
    "\n",
    "- 方案1（SmolAgent::CodeAgent）：封装规划+多步推理，`use_structured_outputs_internally` 决定输出格式（叙事式 vs JSON）。自带 `@tool` 装饰、流式打印，适合想要自动规划、教学演示或快速接 UI 的场景。\n",
    "\n",
    "- 方案2（LangGraph）：用显式状态机把 LLM 节点与 `ToolNode` 串起来，`tools_condition` 控制循环；便于插入过滤/重排/裁剪等治理节点，可视化和监控更友好，适合可编排性与合规要求高的流水线。\n",
    "\n",
    "- 方案3（CodeAgent + MCP）：工具通过 MCP 服务集中托管，前端代理几乎零改动即可复用跨项目/多语言工具；适合团队内统一工具治理、远程扩展或把工具独立部署成服务。\n",
    "\n",
    "- 选型指南：\n",
    "\n",
    "  - 快速内嵌或最小依赖：选方案0。\n",
    "\n",
    "  - 需要自动规划、流式展示或教学：选方案1。\n",
    "\n",
    "  - 流程复杂、需可视化/治理节点：选方案2。\n",
    "\n",
    "  - 工具要集中化、跨项目共享或远程调用：选方案3。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
