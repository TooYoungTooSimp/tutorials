{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ba230c",
   "metadata": {},
   "source": [
    "# Easy Agent Tutorial\n",
    "This notebook file provide three examples of using LLM based agents with different tool sets.\n",
    "\n",
    "prequisites:\n",
    "- Python 3.10+\n",
    "- Install required packages:\n",
    "  ```bash\n",
    "  pip install -r \"mcp[cli]\" smolagent\n",
    "  ```\n",
    "\n",
    "## Task Description\n",
    "\n",
    "如README所述，该项目应用三种方案，从不同的角度实现了agentic RAG的功能。为了演示，这一次我们将会构建一个信安四大会的查询，来进行感兴趣论文的搜索以及基于题目选择合适的会议进行投稿。\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a91a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们将使用dblp数据集来进行演示。首先下载四大会最近几年的会议论文数据：\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"dblp_sec_papers.json\"):\n",
    "    with requests.Session() as sess:\n",
    "        url = \"https://dblp.org/search/publ/api\"\n",
    "        params = {\"q\": \"security\", \"format\": \"json\"}\n",
    "        tocs = {\n",
    "            \"ndss\": \"toc:db/conf/ndss/ndss2025.bht:\",\n",
    "            \"sp\": \"toc:db/conf/sp/sp2025.bht:\",\n",
    "            \"ccs\": \"toc:db/conf/ccs/ccs2025.bht:\",\n",
    "            \"usenix\": \"toc:db/conf/uss/uss2025.bht:\",\n",
    "        }\n",
    "        papers = []\n",
    "        for k, v in tocs.items():\n",
    "            response = sess.get(url, params={\"q\": v, \"h\": 1000, \"format\": \"json\"})\n",
    "            data = response.json()\n",
    "            data = data[\"result\"][\"hits\"][\"hit\"]\n",
    "            papers.extend(data)\n",
    "        with open(f\"dblp_sec_papers.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "else:\n",
    "    with open(f\"dblp_sec_papers.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        papers = json.load(f)\n",
    "papers = [x[\"info\"] for x in papers]\n",
    "titles = [f\"[{x['venue']} {x['year']}] {x['title']}\" for x in papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff07b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建并保存向量数据库\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "if \"db\" not in globals():\n",
    "    db = FAISS.from_texts(titles, OpenAIEmbeddings())\n",
    "db.save_local(\"faiss_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0352eb4d",
   "metadata": {},
   "source": [
    "在开始之前，先看一下传统的工具调用大概长啥样，有怎样的优缺点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ba0df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"kw\":\"blockchain LLM papers\"}', call_id='call_ZNk69x2z6uSxuPEyhldVmhRc', name='query_db', type='function_call', id='fc_0edcc91604d6e0a4006938e28cf5c0819282e662d761ad49ea', status='completed')]\n",
      "Keyword: blockchain LLM papers\n",
      "Searching for keyword: blockchain\n",
      "Searching for keyword: LLM\n",
      "Searching for keyword: papers\n",
      "kw='blockchain LLM papers' appended.\n",
      "你这个方向目前还比较前沿，严格意义上“区块链 × LLM”的论文不算多，但已经有几类比较典型的结合方式，可以按“区块链为LLM赋能”和“LLM为区块链赋能”来找文献。我先列代表性论文和关键词，方便你自己去搜（Google Scholar / arXiv / dblp），再给你一个按方向分类的阅读建议。\n",
      "\n",
      "下面所有英文标题你直接复制去搜索就能找到 PDF。\n",
      "\n",
      "---\n",
      "\n",
      "## 一、LLM 为区块链赋能（用 LLM 做智能合约/链上安全/分析）\n",
      "\n",
      "### 1. 智能合约分析与形式化验证\n",
      "\n",
      "- **PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation**  \n",
      "  NDSS 2025（网络与分布式系统安全研讨会）  \n",
      "  关键词：  \n",
      "  - “LLM-driven Formal Verification of Smart Contracts”  \n",
      "  - “Retrieval-Augmented Property Generation”  \n",
      "  核心思路：用 LLM 自动生成合约的安全属性 / 规范，再结合形式化验证工具检查。适合关注“LLM + 智能合约安全”的同学。\n",
      "\n",
      "- 可一并检索的关键词：  \n",
      "  - “LLM for smart contract auditing”  \n",
      "  - “LLM-based smart contract vulnerability detection”  \n",
      "  - “GPT-4 for smart contract analysis”  \n",
      "\n",
      "很多不是顶会论文，而是 arXiv / 工程论文，但实用性强。\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 区块链安全、交易/地址分析\n",
      "\n",
      "- **Towards Explainable and Effective Anti-Money Laundering for Cryptocurrency**  \n",
      "  CCS 2025（计算机与通信安全大会）  \n",
      "  虽然标题没直接写 LLM，但工作里会用到深度学习/自然语言特征做可解释反洗钱；你可以配合以下关键词找更直接用 LLM 的：\n",
      "\n",
      "  推荐额外检索：\n",
      "  - “LLM for cryptocurrency transaction analysis”  \n",
      "  - “LLM-based blockchain address classification”  \n",
      "  - “LLM for DeFi risk analysis”\n",
      "\n",
      "- **Ghost Clusters: Evaluating Attribution of Illicit Services through Cryptocurrency Tracing**  \n",
      "  USENIX Security 2025  \n",
      "  主体是链上追踪和聚类，但你可以把它当成数据集/方法基础，再看后续有没有工作用 LLM 做实体归属、标签生成。\n",
      "\n",
      "---\n",
      "\n",
      "### 3. LLM 辅助 Web3/合约开发生命周期\n",
      "\n",
      "这些大多是 2023–2025 的 arXiv/Workshop 论文，可以用关键词搜：\n",
      "\n",
      "- “RAG for smart contract development”  \n",
      "- “LLM-powered Web3 development assistant”  \n",
      "- “LLM-based DeFi protocol analysis”\n",
      "\n",
      "可以重点找几个典型的：\n",
      "- “Using ChatGPT/GPT-4 for smart contract development: empirical study”\n",
      "- “LLM-based assistant for Solidity debugging”\n",
      "\n",
      "---\n",
      "\n",
      "## 二、区块链为 LLM 赋能（用区块链做 LLM 的激励/溯源/对齐）\n",
      "\n",
      "目前主流会议里“真正把 LLM 和链耦合在协议里”的工作还比较少，多数在 arXiv / 行业白皮书，典型方向包括：\n",
      "\n",
      "### 1. 模型溯源、版权与水印登记\n",
      "\n",
      "关键词可以这样搜：\n",
      "\n",
      "- “blockchain-based provenance for LLM outputs”  \n",
      "- “on-chain provenance for AI-generated content”  \n",
      "- “blockchain watermarking LLM text”  \n",
      "\n",
      "可以和这类论文一起看（虽然不一定都上链，但概念相近）：\n",
      "- **Provably Robust Multi-bit Watermarking for AI-generated Text**  \n",
      "  NDSS 2025  \n",
      "  再结合 “blockchain for robust watermark registry” 会有一些后续工作。\n",
      "\n",
      "### 2. 分布式/去中心化 LLM 训练与推理激励\n",
      "\n",
      "典型关键词（很多是 arXiv / 项目白皮书）：\n",
      "- “decentralized training of LLM with blockchain incentives”  \n",
      "- “token-incentivized LLM inference marketplace”  \n",
      "- “blockchain-based federated learning for LLM”  \n",
      "\n",
      "可以找类似：\n",
      "- “Bittensor: A Peer-to-Peer Market for Machine Intelligence”（项目白皮书/论文，典型“区块链 + 模型市场”）\n",
      "- “Gensyn” / “Akash AI” 等会有分布式算力+AI 的论文/白皮书\n",
      "\n",
      "---\n",
      "\n",
      "## 三、“安全视角”下的区块链 × LLM（安全圈目前最活跃）\n",
      "\n",
      "这些不是“在协议层面紧密耦合”的区块链+LLM，但对你理解安全问题很有帮助：\n",
      "\n",
      "### 1. LLM 帮你搞区块链安全\n",
      "\n",
      "- **YuraScanner: Leveraging LLMs for Task-driven Web App Scanning**  \n",
      "  NDSS 2025  \n",
      "  侧重点是 Web 安全扫描，但方法可以迁移到 Web3 前端 / 钱包 DApp 安全扫描。\n",
      "\n",
      "- “LLM-based fuzzing for smart contracts”  \n",
      "  可以和下面这篇一起看思路：  \n",
      "  - **Hybrid Language Processor Fuzzing via LLM-Based Constraint Solving**  \n",
      "    USENIX Security 2025  \n",
      "\n",
      "### 2. 区块链场景中的 LLM 风险（间接交叉）\n",
      "\n",
      "当你用 LLM 去构建 Web3 应用时，这类论文里讲的攻击/防御很关键：\n",
      "\n",
      "- **When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs**  \n",
      "  USENIX Security 2025  \n",
      "  适用于 “有钱包 / 区块链读写能力的 Agent” 场景安全分析。\n",
      "\n",
      "- **On the (In)Security of LLM App Stores** – S&P 2025  \n",
      "  如果你构建“插件化的 Web3 Agent 商店”，这里的威胁模型可以直接借用。\n",
      "\n",
      "- 一些对 LLM 越狱、安全性、隐私的论文：  \n",
      "  - SelfDefend, PAPILLON, Activation Approximations…, PrivacyXray, Private Investigator, TracLLM 等（USENIX / NDSS / S&P 2025）  \n",
      "  在设计“链上 Agent DAO”“自治交易机器人”时，LLM 的安全问题会直接映射成资金风险。\n",
      "\n",
      "---\n",
      "\n",
      "## 四、给你一个检索策略（方便你扩展）\n",
      "\n",
      "你可以这样在 Google Scholar / arXiv 搜：\n",
      "\n",
      "1. 直接搜组合关键词：\n",
      "   - `\"blockchain\" \"large language model\"`  \n",
      "   - `\"web3\" \"large language model\"`  \n",
      "   - `\"smart contract\" \"large language model\"`  \n",
      "   - `\"DeFi\" \"large language model\"`  \n",
      "\n",
      "2. 指定近两年时间：\n",
      "   - Google Scholar 左侧 “Since 2023 / 2024 / 2025”\n",
      "\n",
      "3. 结合你关心的子方向：\n",
      "   - 安全：`\"LLM\" \"smart contract security\"` / `\"LLM\" \"DeFi risk\"`  \n",
      "   - 激励与协议：`\"LLM marketplace\" \"blockchain\"`  \n",
      "   - 隐私与合规：`\"on-chain provenance\" \"LLM\"` / `\"GDPR\" \"LLM\" \"blockchain\"`\n",
      "\n",
      "---\n",
      "\n",
      "## 五、如果你告诉我更细的兴趣，我可以给你“精读清单”\n",
      "\n",
      "比如你更偏向：\n",
      "\n",
      "- 做“LLM 辅助智能合约审计/验证”  \n",
      "- 做“去中心化 LLM / 模型市场 / Agent DAO 协议设计”  \n",
      "- 或者“用区块链做 LLM 输出的溯源、版权和监管”\n",
      "\n",
      "你说一下具体方向，我可以帮你整理一个更窄的 5–10 篇“必读 + 可选”列表，并按阅读顺序、重点 section 给你标出来。\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import re\n",
    "\n",
    "import dotenv\n",
    "import tenacity\n",
    "import yaml\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "from openai.types import *\n",
    "from openai.types.chat import *\n",
    "\n",
    "\n",
    "def raw_toolcall():\n",
    "    client = OpenAI()\n",
    "    db = FAISS.load_local(\n",
    "        \"faiss_db\",\n",
    "        OpenAIEmbeddings(),\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "    tools_def = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"name\": \"query_db\",\n",
    "            \"description\": \"accept keyword and return related information\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"kw\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The keyword to query the database\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"kw\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    def real_ask(question: str):\n",
    "        from openai.types.responses.response_input_param import Message\n",
    "\n",
    "        input_msgs: list[Message] = [\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are a helpful research assistant. When given a question, you must first decide if you need to query the database to get relevant information. If so, use the tool 'query_db' with appropriate keywords extracted from the question. After getting the information, provide a comprehensive answer based on both the retrieved information and your own knowledge.\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            },\n",
    "        ]\n",
    "        resp = client.responses.create(\n",
    "            model=\"gpt-5.1\",\n",
    "            tools=tools_def,\n",
    "            input=input_msgs,\n",
    "            tool_choice=\"required\",\n",
    "        )\n",
    "        print(resp.output)\n",
    "        for toolcall in resp.output:\n",
    "            if toolcall.type != \"function_call\":\n",
    "                continue\n",
    "            if toolcall.name == \"query_db\":\n",
    "                kw = json.loads(toolcall.arguments)[\"kw\"]\n",
    "                print(f\"Keyword: {kw}\")\n",
    "                docs = []\n",
    "                for skw in kw.split():\n",
    "                    if not (skw := skw.strip()):\n",
    "                        continue\n",
    "                    print(f\"Searching for keyword: {skw}\")\n",
    "                    docs.extend(db.similarity_search(skw, k=30))\n",
    "                rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "                input_msgs.append(toolcall)\n",
    "                input_msgs.append(\n",
    "                    {\n",
    "                        \"type\": \"function_call_output\",\n",
    "                        \"call_id\": toolcall.call_id,\n",
    "                        \"output\": str(rag_result),\n",
    "                    }\n",
    "                )\n",
    "                print(f\"{kw=} appended.\")\n",
    "        if input_msgs[-1][\"type\"] == \"function_call_output\":\n",
    "            resp = client.responses.create(\n",
    "                model=\"gpt-5.1\",\n",
    "                input=input_msgs,\n",
    "                # tools=tools_def,\n",
    "                stream=True,\n",
    "            )\n",
    "            for chunk in resp:\n",
    "                if chunk.type == \"response.output_text.delta\":\n",
    "                    print(chunk.delta, end=\"\", flush=True)\n",
    "            print()\n",
    "        else:\n",
    "            print(resp.output_text)\n",
    "\n",
    "    while True:\n",
    "        inp = input(\"=> \")\n",
    "        if not inp.strip():\n",
    "            break\n",
    "        real_ask(inp)\n",
    "\n",
    "\n",
    "raw_toolcall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0f2b1",
   "metadata": {},
   "source": [
    "### 传统工具调用的优缺点\n",
    "\n",
    "- 优点：直接用模型原生的 function/tool 调用协议，链路短、开销低，JSON Schema 参数校验清晰。\n",
    "- 优点：可以精确控制何时调用工具、使用 `tool_choice` 等参数强制执行，消息格式透明、便于调试和流式输出。\n",
    "- 优点：依赖少，不绑框架，易于插入到现有服务或与其他编排层组合。\n",
    "- 缺点：需要手写对话状态管理、工具输入输出拼接，容易出错且样板代码多。\n",
    "- 缺点：缺少自动规划/多步推理、重试、fallback 等封装能力，复杂流程要自行实现。\n",
    "- 缺点：与特定模型/协议耦合，换提供方或多模型时需适配；安全性与数据清洗（如反序列化、去重）也要自管。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888af19",
   "metadata": {},
   "source": [
    "## SmolAgent::CodeAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d330b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You are a helpful research assistant. When given a question, you must first decide if you need to query the </span>    <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">database to get relevant information. If so, use the tool 'query_db' with appropriate keywords extracted from </span>  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">the question. After getting the information, provide a comprehensive answer based on both the retrieved </span>        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">information and your own knowledge.</span>                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">找一下llm安全的论文</span>                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIModel - gpt-5.1 ─────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou are a helpful research assistant. When given a question, you must first decide if you need to query the \u001b[0m    \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mdatabase to get relevant information. If so, use the tool 'query_db' with appropriate keywords extracted from \u001b[0m  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mthe question. After getting the information, provide a comprehensive answer based on both the retrieved \u001b[0m        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1minformation and your own knowledge.\u001b[0m                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m找一下llm安全的论文\u001b[0m                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIModel - gpt-5.1 \u001b[0m\u001b[38;2;212;183;2m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef5d6551a0648f796be15699d47d6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Thought:</span><span style=\"background-color: #272822\">                                                                                                     </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The user is asking in Chinese: \"找一下llm安全的论文\" = \"Find some papers on LLM security.\"</span><span style=\"background-color: #272822\">                   </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># I should query the database using relevant English keywords like \"LLM security\", \"large language model </span><span style=\"background-color: #272822\">      </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\">security\", \"jailbreak attacks\", etc.</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># I'll start with a broad keyword \"LLM security\" to get related paper titles.</span><span style=\"background-color: #272822\">                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers_llm_security </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> query_db(kw</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"LLM security\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                              </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(papers_llm_security)</span><span style=\"background-color: #272822\">                                                                                     </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Thought:\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# The user is asking in Chinese: \"找一下llm安全的论文\" = \"Find some papers on LLM security.\"\u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# I should query the database using relevant English keywords like \"LLM security\", \"large language model \u001b[0m\u001b[48;2;39;40;34m      \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34msecurity\", \"jailbreak attacks\", etc.\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# I'll start with a broad keyword \"LLM security\" to get related paper titles.\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mpapers_llm_security\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery_db\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkw\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mLLM security\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                              \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers_llm_security\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for keyword: LLM\n",
      "Searching for keyword: security\n",
      "Searching for keyword: security\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\n",
       "[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection.\n",
       "[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain.\n",
       "[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.\n",
       "[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\n",
       "[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\n",
       "[SP 2025] On the (In)Security of LLM App Stores.\n",
       "[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones\n",
       "with mmWave Radar.\n",
       "[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\n",
       "[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by \n",
       "Code Generating LLMs.\n",
       "[USENIX Security Symposium 2025] Understanding How Users Prepare for and React to Smartphone Theft.\n",
       "[USENIX Security Symposium 2025] Digital Security Perceptions and Practices Around the World: A WEIRD versus \n",
       "Non-WEIRD Comparison.\n",
       "[USENIX Security Symposium 2025] A First Look at Governments&amp;apos; Enterprise Security Guidance.\n",
       "[SP 2025] &amp;quot;It&amp;apos;s Time. Time for Digital Security.&amp;quot;: An End User Study on Actionable Security and \n",
       "Privacy Advice.\n",
       "[USENIX Security Symposium 2025] Scanned and Scammed: Insecurity by ObsQRity? Measuring User Susceptibility and \n",
       "Awareness of QR Code-Based Attacks.\n",
       "[SP 2025] Code Speaks Louder: Exploring Security and Privacy Relevant Regional Variations in Mobile Applications.\n",
       "[USENIX Security Symposium 2025] A Stakeholder-Based Framework to Highlight Tensions when Implementing Privacy \n",
       "Features.\n",
       "[USENIX Security Symposium 2025] &amp;quot;No, I Can&amp;apos;t Be a Security Personnel on Your Phone&amp;quot;: Security and \n",
       "Privacy Threats From Sharing Infrastructure in Rural Ghana.\n",
       "[USENIX Security Symposium 2025] Too Much of a Good Thing: (In-)Security of Mandatory Security Software for \n",
       "Financial Services in South Korea.\n",
       "[SP 2025] Open Sesame! On the Security and Memorability of Verbal Passwords.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\n",
       "[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection.\n",
       "[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain.\n",
       "[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.\n",
       "[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\n",
       "[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\n",
       "[SP 2025] On the (In)Security of LLM App Stores.\n",
       "[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones\n",
       "with mmWave Radar.\n",
       "[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\n",
       "[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by \n",
       "Code Generating LLMs.\n",
       "[USENIX Security Symposium 2025] Understanding How Users Prepare for and React to Smartphone Theft.\n",
       "[USENIX Security Symposium 2025] Digital Security Perceptions and Practices Around the World: A WEIRD versus \n",
       "Non-WEIRD Comparison.\n",
       "[USENIX Security Symposium 2025] A First Look at Governments&apos; Enterprise Security Guidance.\n",
       "[SP 2025] &quot;It&apos;s Time. Time for Digital Security.&quot;: An End User Study on Actionable Security and \n",
       "Privacy Advice.\n",
       "[USENIX Security Symposium 2025] Scanned and Scammed: Insecurity by ObsQRity? Measuring User Susceptibility and \n",
       "Awareness of QR Code-Based Attacks.\n",
       "[SP 2025] Code Speaks Louder: Exploring Security and Privacy Relevant Regional Variations in Mobile Applications.\n",
       "[USENIX Security Symposium 2025] A Stakeholder-Based Framework to Highlight Tensions when Implementing Privacy \n",
       "Features.\n",
       "[USENIX Security Symposium 2025] &quot;No, I Can&apos;t Be a Security Personnel on Your Phone&quot;: Security and \n",
       "Privacy Threats From Sharing Infrastructure in Rural Ghana.\n",
       "[USENIX Security Symposium 2025] Too Much of a Good Thing: (In-)Security of Mandatory Security Software for \n",
       "Financial Services in South Korea.\n",
       "[SP 2025] Open Sesame! On the Security and Memorability of Verbal Passwords.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 21.45 seconds| Input tokens: 2,077 | Output tokens: 1,485]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 21.45 seconds| Input tokens: 2,077 | Output tokens: 1,485]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cfb35060ed487e9ae232368d7aefbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Thought:</span><span style=\"background-color: #272822\">                                                                                                     </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># We already queried the DB with \"LLM security\" and obtained a list of recent security conference papers.</span><span style=\"background-color: #272822\">      </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Now I’ll (1) filter out the most relevant LLM安全-related ones, and (2) summarize them + give reading </span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\">suggestions.</span><span style=\"background-color: #272822\">                                                                                                   </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># No further DB queries are needed; I'll directly construct the final answer.</span><span style=\"background-color: #272822\">                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers_raw </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> [</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge </span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Injection.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical </span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Domain.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a </span><span style=\"background-color: #272822\">        </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Practical Manner.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] On the (In)Security of LLM App Stores.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                        </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction </span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Headphones with mmWave Radar.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package </span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Hallucinations by Code Generating LLMs.\"</span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                                                              </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">llm_papers </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> papers_raw  </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># all are LLM-related in some way</span><span style=\"background-color: #272822\">                                                     </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> pprint </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> pprint</span><span style=\"background-color: #272822\">                                                                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">pprint(llm_papers)</span><span style=\"background-color: #272822\">                                                                                             </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Thought:\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# We already queried the DB with \"LLM security\" and obtained a list of recent security conference papers.\u001b[0m\u001b[48;2;39;40;34m      \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Now I’ll (1) filter out the most relevant LLM安全-related ones, and (2) summarize them + give reading \u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34msuggestions.\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# No further DB queries are needed; I'll directly construct the final answer.\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mpapers_raw\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge \u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mInjection.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mDomain.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mPractical Manner.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] On the (In)Security of LLM App Stores.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mHeadphones with mmWave Radar.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mHallucinations by Code Generating LLMs.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mllm_papers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers_raw\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# all are LLM-related in some way\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpprint\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mpprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mllm_papers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                             \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Code execution failed at line 'from pprint import pprint' due to: InterpreterError: Import from pprint is not </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">allowed. Authorized imports are: ['unicodedata', 'itertools', 'queue', 'random', 'collections', 'time', </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'statistics', 're', 'stat', 'datetime', 'math'\\]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mCode execution failed at line 'from pprint import pprint' due to: InterpreterError: Import from pprint is not \u001b[0m\n",
       "\u001b[1;31mallowed. Authorized imports are: ['unicodedata', 'itertools', 'queue', 'random', 'collections', 'time', \u001b[0m\n",
       "\u001b[1;31m'statistics', 're', 'stat', 'datetime', 'math'\\]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 24.21 seconds| Input tokens: 6,348 | Output tokens: 3,814]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 24.21 seconds| Input tokens: 6,348 | Output tokens: 3,814]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac32697f508541ca927d684a6e1b2882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># 列出刚才从数据库中得到的、和 LLM 强相关的安全论文</span><span style=\"background-color: #272822\">                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">llm_papers </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> [</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge </span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Injection.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical </span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Domain.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a </span><span style=\"background-color: #272822\">        </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Practical Manner.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] On the (In)Security of LLM App Stores.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                        </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction </span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Headphones with mmWave Radar.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package </span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Hallucinations by Code Generating LLMs.\"</span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                                                              </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">for</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> p </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> llm_papers:</span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    print(p)</span><span style=\"background-color: #272822\">                                                                                                   </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# 列出刚才从数据库中得到的、和 LLM 强相关的安全论文\u001b[0m\u001b[48;2;39;40;34m                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mllm_papers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge \u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mInjection.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mDomain.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mPractical Manner.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] On the (In)Security of LLM App Stores.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mHeadphones with mmWave Radar.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mHallucinations by Code Generating LLMs.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;102;217;239;48;2;39;40;34mfor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mp\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mllm_papers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mp\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\n",
       "[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection.\n",
       "[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain.\n",
       "[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.\n",
       "[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\n",
       "[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\n",
       "[SP 2025] On the (In)Security of LLM App Stores.\n",
       "[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones\n",
       "with mmWave Radar.\n",
       "[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\n",
       "[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by \n",
       "Code Generating LLMs.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\n",
       "[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection.\n",
       "[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain.\n",
       "[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.\n",
       "[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\n",
       "[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\n",
       "[SP 2025] On the (In)Security of LLM App Stores.\n",
       "[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones\n",
       "with mmWave Radar.\n",
       "[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\n",
       "[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by \n",
       "Code Generating LLMs.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 18.76 seconds| Input tokens: 13,502 | Output tokens: 5,684]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 18.76 seconds| Input tokens: 13,502 | Output tokens: 5,684]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 4</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 4\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979fc6a23c25489fb60bc72fee220275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> collections </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> defaultdict</span><span style=\"background-color: #272822\">                                                                            </span>  \n",
       "  <span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> datetime </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> datetime</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">llm_papers </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> [</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge </span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Injection.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical </span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Domain.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a </span><span style=\"background-color: #272822\">        </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Practical Manner.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] On the (In)Security of LLM App Stores.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                        </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction </span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Headphones with mmWave Radar.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package </span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Hallucinations by Code Generating LLMs.\"</span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                                                              </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">summary </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> {</span><span style=\"background-color: #272822\">                                                                                                    </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"time_generated\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: datetime</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">utcnow()</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">isoformat() </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">+</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Z\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                     </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"count\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: len(llm_papers),</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"papers\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: llm_papers,</span><span style=\"background-color: #272822\">                                                                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                              </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(summary)</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcollections\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdefaultdict\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m  \n",
       "  \u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdatetime\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdatetime\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mllm_papers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge \u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mInjection.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mDomain.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mPractical Manner.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] On the (In)Security of LLM App Stores.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mHeadphones with mmWave Radar.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mHallucinations by Code Generating LLMs.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34msummary\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtime_generated\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdatetime\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mutcnow\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34misoformat\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m+\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mZ\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcount\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlen\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mllm_papers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mllm_papers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msummary\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "{'time_generated': '2025-12-10T03:27:07.028849Z', 'count': 10, 'papers': ['[USENIX Security Symposium 2025] When \n",
       "LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.', '[CCS 2025] Give LLMs a Security Course: Securing \n",
       "Retrieval-Augmented Code Generation via Knowledge Injection.', '[CCS 2025] Can Personal Health Information Be \n",
       "Secured in LLM? Privacy Attack and Defense in the Medical Domain.', '[USENIX Security Symposium 2025] SelfDefend: \n",
       "LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.', '[NDSS 2025] LLMPirate: LLMs for Black-box\n",
       "Hardware IP Piracy.', '[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command \n",
       "Explainer.', '[SP 2025] On the (In)Security of LLM App Stores.', '[USENIX Security Symposium 2025] EchoLLM: \n",
       "LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar.', '[SP 2025] \n",
       "Alleviating the Fear of Losing Alignment in LLM Fine-tuning.', '[USENIX Security Symposium 2025] We Have a Package \n",
       "for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs.']}\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "{'time_generated': '2025-12-10T03:27:07.028849Z', 'count': 10, 'papers': ['[USENIX Security Symposium 2025] When \n",
       "LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.', '[CCS 2025] Give LLMs a Security Course: Securing \n",
       "Retrieval-Augmented Code Generation via Knowledge Injection.', '[CCS 2025] Can Personal Health Information Be \n",
       "Secured in LLM? Privacy Attack and Defense in the Medical Domain.', '[USENIX Security Symposium 2025] SelfDefend: \n",
       "LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.', '[NDSS 2025] LLMPirate: LLMs for Black-box\n",
       "Hardware IP Piracy.', '[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command \n",
       "Explainer.', '[SP 2025] On the (In)Security of LLM App Stores.', '[USENIX Security Symposium 2025] EchoLLM: \n",
       "LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar.', '[SP 2025] \n",
       "Alleviating the Fear of Losing Alignment in LLM Fine-tuning.', '[USENIX Security Symposium 2025] We Have a Package \n",
       "for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs.']}\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 4: Duration 27.02 seconds| Input tokens: 23,196 | Output tokens: 8,033]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 4: Duration 27.02 seconds| Input tokens: 23,196 | Output tokens: 8,033]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 5</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 5\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64ffd6d3e2843b4aa54998f7fd3af59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Thought:</span><span style=\"background-color: #272822\">                                                                                                     </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># We have the list of 10 LLM 安全相关论文和一个简单的 summary。</span><span style=\"background-color: #272822\">                                                </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># 不再需要执行代码，直接用 final_answer 返回给用户一个精炼的中文总结和论文清单。</span><span style=\"background-color: #272822\">                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> datetime </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> datetime</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> [</span><span style=\"background-color: #272822\">                                                                                                     </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge </span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Injection.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical </span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Domain.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a </span><span style=\"background-color: #272822\">        </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Practical Manner.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] On the (In)Security of LLM App Stores.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                        </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction </span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Headphones with mmWave Radar.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package </span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Hallucinations by Code Generating LLMs.\"</span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                                                              </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">answer_text </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">f\"\"\"我帮你从数据库里找到了 **LLM 安全方向、2025 年顶会** 的代表性论文（USENIX Security / CCS / </span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">NDSS / IEEE S&amp;P），可以直接用这些英文题目去 Google Scholar、arXiv 或对应会议官网搜 PDF：</span><span style=\"background-color: #272822\">                       </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">一、联网 / 平台生态安全</span><span style=\"background-color: #272822\">                                                                                        </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">1. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - When LLMs Go Online: Web-enabled LLM 带来的新型攻击面（联网访问网页、API 之后的安全问题）。</span><span style=\"background-color: #272822\">               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">2. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">6</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - On the (In)Security of LLM App Stores: 研究 LLM 应用商店 / 插件生态中的安全风险（恶意 App、权限滥用等）。</span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">二、Jailbreak 与对齐安全</span><span style=\"background-color: #272822\">                                                                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">3. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">3</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner</span><span style=\"background-color: #272822\">                         </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - 关注越狱攻击（jailbreak）的防御，让 LLM 具备自我防护能力。</span><span style=\"background-color: #272822\">                                                </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">4. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">8</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - Alleviating the Fear of Losing Alignment in LLM Fine-tuning</span><span style=\"background-color: #272822\">                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - 研究微调过程中对齐（alignment）丢失的问题，以及如何缓解。</span><span style=\"background-color: #272822\">                                                 </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">三、隐私与敏感领域（医疗）</span><span style=\"background-color: #272822\">                                                                                     </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">5. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain</span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - 医疗场景下的 LLM 隐私攻击与防御，关注个人健康信息（PHI）的泄露风险。</span><span style=\"background-color: #272822\">                                      </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">四、代码安全与供应链</span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">6. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection</span><span style=\"background-color: #272822\">         </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - RAG + 代码生成场景，通过注入安全知识来减少不安全代码。</span><span style=\"background-color: #272822\">                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">7. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">9</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs</span><span style=\"background-color: #272822\">     </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - 分析代码 LLM 产生“虚构依赖包（package hallucination）”带来的供应链安全风险。</span><span style=\"background-color: #272822\">                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">8. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">5</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer</span><span style=\"background-color: #272822\">                  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - LLM 驱动的 shell 命令解释器，可视为安全辅助工具（帮助用户理解可能有风险的命令）。</span><span style=\"background-color: #272822\">                         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">五、LLM 辅助攻击 / 知识产权安全</span><span style=\"background-color: #272822\">                                                                                </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">9. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">4</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - LLMPirate: LLMs for Black-box Hardware IP Piracy</span><span style=\"background-color: #272822\">                                                          </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - 利用 LLM 辅助进行黑盒硬件 IP 盗取，是“LLM 被攻击者利用”的典型案例。</span><span style=\"background-color: #272822\">                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">10. {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">papers[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">7</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">    - EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar</span><span style=\"background-color: #272822\">     </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">    - LLM 参与声学/侧信道窃听攻击，展示 LLM 在攻击链中的增强作用。</span><span style=\"background-color: #272822\">                                             </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">如果你告诉我你更想做哪一块（比如「越狱防御」「RAG + 安全」「医疗隐私」「代码安全」），我可以在这 10 </span><span style=\"background-color: #272822\">           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">篇的基础上，再帮你补充 2023–2024 年比较经典的 LLM 安全论文，顺便给你一条适合作为开题/综述的阅读路线。</span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(answer_text)</span><span style=\"background-color: #272822\">                                                                                      </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Thought:\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# We have the list of 10 LLM 安全相关论文和一个简单的 summary。\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# 不再需要执行代码，直接用 final_answer 返回给用户一个精炼的中文总结和论文清单。\u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdatetime\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdatetime\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge \u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mInjection.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mDomain.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mPractical Manner.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] On the (In)Security of LLM App Stores.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mHeadphones with mmWave Radar.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mHallucinations by Code Generating LLMs.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34manswer_text\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mf\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m我帮你从数据库里找到了 **LLM 安全方向、2025 年顶会** 的代表性论文（USENIX Security / CCS / \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mNDSS / IEEE S&P），可以直接用这些英文题目去 Google Scholar、arXiv 或对应会议官网搜 PDF：\u001b[0m\u001b[48;2;39;40;34m                       \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m一、联网 / 平台生态安全\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m1. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - When LLMs Go Online: Web-enabled LLM 带来的新型攻击面（联网访问网页、API 之后的安全问题）。\u001b[0m\u001b[48;2;39;40;34m               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m2. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m6\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - On the (In)Security of LLM App Stores: 研究 LLM 应用商店 / 插件生态中的安全风险（恶意 App、权限滥用等）。\u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m二、Jailbreak 与对齐安全\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m3. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m3\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner\u001b[0m\u001b[48;2;39;40;34m                         \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - 关注越狱攻击（jailbreak）的防御，让 LLM 具备自我防护能力。\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m4. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m8\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - Alleviating the Fear of Losing Alignment in LLM Fine-tuning\u001b[0m\u001b[48;2;39;40;34m                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - 研究微调过程中对齐（alignment）丢失的问题，以及如何缓解。\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m三、隐私与敏感领域（医疗）\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m5. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - 医疗场景下的 LLM 隐私攻击与防御，关注个人健康信息（PHI）的泄露风险。\u001b[0m\u001b[48;2;39;40;34m                                      \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m四、代码安全与供应链\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m6. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection\u001b[0m\u001b[48;2;39;40;34m         \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - RAG + 代码生成场景，通过注入安全知识来减少不安全代码。\u001b[0m\u001b[48;2;39;40;34m                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m7. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m9\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs\u001b[0m\u001b[48;2;39;40;34m     \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - 分析代码 LLM 产生“虚构依赖包（package hallucination）”带来的供应链安全风险。\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m8. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m5\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer\u001b[0m\u001b[48;2;39;40;34m                  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - LLM 驱动的 shell 命令解释器，可视为安全辅助工具（帮助用户理解可能有风险的命令）。\u001b[0m\u001b[48;2;39;40;34m                         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m五、LLM 辅助攻击 / 知识产权安全\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m9. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m4\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - LLMPirate: LLMs for Black-box Hardware IP Piracy\u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - 利用 LLM 辅助进行黑盒硬件 IP 盗取，是“LLM 被攻击者利用”的典型案例。\u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m10. \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpapers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m7\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m    - EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar\u001b[0m\u001b[48;2;39;40;34m     \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m    - LLM 参与声学/侧信道窃听攻击，展示 LLM 在攻击链中的增强作用。\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m如果你告诉我你更想做哪一块（比如「越狱防御」「RAG + 安全」「医疗隐私」「代码安全」），我可以在这 10 \u001b[0m\u001b[48;2;39;40;34m           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m篇的基础上，再帮你补充 2023–2024 年比较经典的 LLM 安全论文，顺便给你一条适合作为开题/综述的阅读路线。\u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34manswer_text\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: 我帮你从数据库里找到了 **LLM 安全方向、2025 年顶会** 的代表性论文（USENIX Security / CCS / NDSS / </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">IEEE S&amp;P），可以直接用这些英文题目去 Google Scholar、arXiv 或对应会议官网搜 PDF：</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">一、联网 / 平台生态安全</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">1. [USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - When LLMs Go Online: Web-enabled LLM 带来的新型攻击面（联网访问网页、API 之后的安全问题）。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">2. [SP 2025] On the (In)Security of LLM App Stores.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - On the (In)Security of LLM App Stores: 研究 LLM 应用商店 / 插件生态中的安全风险（恶意 App、权限滥用等）。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">二、Jailbreak 与对齐安全</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">3. [USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Manner.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - 关注越狱攻击（jailbreak）的防御，让 LLM 具备自我防护能力。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">4. [SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - Alleviating the Fear of Losing Alignment in LLM Fine-tuning</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - 研究微调过程中对齐（alignment）丢失的问题，以及如何缓解。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">三、隐私与敏感领域（医疗）</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">5. [CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - 医疗场景下的 LLM 隐私攻击与防御，关注个人健康信息（PHI）的泄露风险。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">四、代码安全与供应链</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">6. [CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - RAG + 代码生成场景，通过注入安全知识来减少不安全代码。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">7. [USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package Hallucinations </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">by Code Generating LLMs.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - 分析代码 LLM 产生“虚构依赖包（package hallucination）”带来的供应链安全风险。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">8. [NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - LLM 驱动的 shell 命令解释器，可视为安全辅助工具（帮助用户理解可能有风险的命令）。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">五、LLM 辅助攻击 / 知识产权安全</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">9. [NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - LLMPirate: LLMs for Black-box Hardware IP Piracy</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - 利用 LLM 辅助进行黑盒硬件 IP 盗取，是“LLM 被攻击者利用”的典型案例。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">10. [USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Headphones with mmWave Radar.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">    - EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">    - LLM 参与声学/侧信道窃听攻击，展示 LLM 在攻击链中的增强作用。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">如果你告诉我你更想做哪一块（比如「越狱防御」「RAG + 安全」「医疗隐私」「代码安全」），我可以在这 10 </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">篇的基础上，再帮你补充 2023–2024 年比较经典的 LLM 安全论文，顺便给你一条适合作为开题/综述的阅读路线。</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: 我帮你从数据库里找到了 **LLM 安全方向、2025 年顶会** 的代表性论文（USENIX Security / CCS / NDSS / \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mIEEE S&P），可以直接用这些英文题目去 Google Scholar、arXiv 或对应会议官网搜 PDF：\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m一、联网 / 平台生态安全\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m1. [USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - When LLMs Go Online: Web-enabled LLM 带来的新型攻击面（联网访问网页、API 之后的安全问题）。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m2. [SP 2025] On the (In)Security of LLM App Stores.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - On the (In)Security of LLM App Stores: 研究 LLM 应用商店 / 插件生态中的安全风险（恶意 App、权限滥用等）。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m二、Jailbreak 与对齐安全\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m3. [USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mManner.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - 关注越狱攻击（jailbreak）的防御，让 LLM 具备自我防护能力。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m4. [SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - Alleviating the Fear of Losing Alignment in LLM Fine-tuning\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - 研究微调过程中对齐（alignment）丢失的问题，以及如何缓解。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m三、隐私与敏感领域（医疗）\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m5. [CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - 医疗场景下的 LLM 隐私攻击与防御，关注个人健康信息（PHI）的泄露风险。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m四、代码安全与供应链\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m6. [CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - RAG + 代码生成场景，通过注入安全知识来减少不安全代码。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m7. [USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package Hallucinations \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mby Code Generating LLMs.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - 分析代码 LLM 产生“虚构依赖包（package hallucination）”带来的供应链安全风险。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m8. [NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - LLM 驱动的 shell 命令解释器，可视为安全辅助工具（帮助用户理解可能有风险的命令）。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m五、LLM 辅助攻击 / 知识产权安全\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m9. [NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - LLMPirate: LLMs for Black-box Hardware IP Piracy\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - 利用 LLM 辅助进行黑盒硬件 IP 盗取，是“LLM 被攻击者利用”的典型案例。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m10. [USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mHeadphones with mmWave Radar.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m    - EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m    - LLM 参与声学/侧信道窃听攻击，展示 LLM 在攻击链中的增强作用。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m如果你告诉我你更想做哪一块（比如「越狱防御」「RAG + 安全」「医疗隐私」「代码安全」），我可以在这 10 \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m篇的基础上，再帮你补充 2023–2024 年比较经典的 LLM 安全论文，顺便给你一条适合作为开题/综述的阅读路线。\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 5: Duration 11.28 seconds| Input tokens: 35,967 | Output tokens: 9,134]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 5: Duration 11.28 seconds| Input tokens: 35,967 | Output tokens: 9,134]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我帮你从数据库里找到了 **LLM 安全方向、2025 年顶会** 的代表性论文（USENIX Security / CCS / NDSS / IEEE S&P），可以直接用这些英文题目去 Google Scholar、arXiv 或对应会议官网搜 PDF：\n",
      "\n",
      "一、联网 / 平台生态安全\n",
      "1. [USENIX Security Symposium 2025] When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs.\n",
      "   - When LLMs Go Online: Web-enabled LLM 带来的新型攻击面（联网访问网页、API 之后的安全问题）。\n",
      "2. [SP 2025] On the (In)Security of LLM App Stores.\n",
      "   - On the (In)Security of LLM App Stores: 研究 LLM 应用商店 / 插件生态中的安全风险（恶意 App、权限滥用等）。\n",
      "\n",
      "二、Jailbreak 与对齐安全\n",
      "3. [USENIX Security Symposium 2025] SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.\n",
      "   - SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner\n",
      "   - 关注越狱攻击（jailbreak）的防御，让 LLM 具备自我防护能力。\n",
      "4. [SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\n",
      "   - Alleviating the Fear of Losing Alignment in LLM Fine-tuning\n",
      "   - 研究微调过程中对齐（alignment）丢失的问题，以及如何缓解。\n",
      "\n",
      "三、隐私与敏感领域（医疗）\n",
      "5. [CCS 2025] Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain.\n",
      "   - Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain\n",
      "   - 医疗场景下的 LLM 隐私攻击与防御，关注个人健康信息（PHI）的泄露风险。\n",
      "\n",
      "四、代码安全与供应链\n",
      "6. [CCS 2025] Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection.\n",
      "   - Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection\n",
      "   - RAG + 代码生成场景，通过注入安全知识来减少不安全代码。\n",
      "7. [USENIX Security Symposium 2025] We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs.\n",
      "   - We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs\n",
      "   - 分析代码 LLM 产生“虚构依赖包（package hallucination）”带来的供应链安全风险。\n",
      "8. [NDSS 2025] RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer.\n",
      "   - RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer\n",
      "   - LLM 驱动的 shell 命令解释器，可视为安全辅助工具（帮助用户理解可能有风险的命令）。\n",
      "\n",
      "五、LLM 辅助攻击 / 知识产权安全\n",
      "9. [NDSS 2025] LLMPirate: LLMs for Black-box Hardware IP Piracy.\n",
      "   - LLMPirate: LLMs for Black-box Hardware IP Piracy\n",
      "   - 利用 LLM 辅助进行黑盒硬件 IP 盗取，是“LLM 被攻击者利用”的典型案例。\n",
      "10. [USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar.\n",
      "    - EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar\n",
      "    - LLM 参与声学/侧信道窃听攻击，展示 LLM 在攻击链中的增强作用。\n",
      "\n",
      "如果你告诉我你更想做哪一块（比如「越狱防御」「RAG + 安全」「医疗隐私」「代码安全」），我可以在这 10 篇的基础上，再帮你补充 2023–2024 年比较经典的 LLM 安全论文，顺便给你一条适合作为开题/综述的阅读路线。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from smolagents import CodeAgent, OpenAIServerModel, tool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    \"faiss_db\",\n",
    "    OpenAIEmbeddings(),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "content = f\"You are a helpful research assistant. When given a question, you must first decide if you need to query the database to get relevant information. If so, use the tool 'query_db' with appropriate keywords extracted from the question. After getting the information, provide a comprehensive answer based on both the retrieved information and your own knowledge.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_db(kw: str) -> str:\n",
    "    \"\"\"\n",
    "    accept keyword and return related paper titles\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword to query the database\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for skw in kw.split():\n",
    "        if not (skw := skw.strip()):\n",
    "            continue\n",
    "        print(f\"Searching for keyword: {skw}\")\n",
    "        docs.extend(db.similarity_search(skw, k=10))\n",
    "    rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return rag_result\n",
    "\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model=OpenAIServerModel(\"gpt-5.1\"),\n",
    "    tools=[query_db],\n",
    "    # verbosity_level=1,\n",
    "    stream_outputs=True,\n",
    ")\n",
    "\n",
    "# from Gradio_UI import GradioUI\n",
    "\n",
    "# GradioUI(agent).launch()\n",
    "\n",
    "print(agent.run(f\"{content}\\n\\n{input(\"=> \")}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5978dc",
   "metadata": {},
   "source": [
    "### 方案说明：SmolAgent::CodeAgent\n",
    "- 核心循环：强制每步遵循 “Thought → Code → Observation”，并用 `{{code_block_opening_tag}}`/`{{code_block_closing_tag}}` 包裹代码。中间信息需用 `print` 显式输出，下一步作为 Observation 读取。最终答案必须调用 `final_answer` 工具收束。\n",
    "- 规划前置：系统 prompt 要求先做 facts survey（已知/待查/待推导）再产出高层计划；若重试或中断，使用 update_plan 模板复盘并继续，保证稳态迭代。\n",
    "- 工具与调用规范：可用工具（Python 函数）被注入环境，必须按显式参数名调用，禁止 dict 传参，禁止使用未定义变量，也禁止变量名与工具同名；对无结构化输出的工具，提示分步打印避免链式依赖。\n",
    "- 安全与约束：限制可导入模块白名单；提醒不要链过多非结构化结果，必要时拆分步；保持会话状态，可多轮复用已导入模块和已定义变量。\n",
    "- 角色定位：将代理设为“能用代码解决任意任务的专家助手”，鼓励用工具+代码完成 RAG 检索、加工与总结；prompt 示例覆盖算术、检索、多模态 QA 等，教会模型如何 Thought/Code/Observation 协同。\n",
    "- 输出与流式：示例强调逐步打印中间结果、最后用 `final_answer` 汇总；若有 stream 开启，能边执行边输出。\n",
    "### 优点\n",
    "- 自带规划、分步执行与错误恢复模板，减少裸 toolcall 的样板与状态管理成本。\n",
    "- Thought/Code/Observation 将思路与代码解耦，便于调试审计；跨步保留状态，适合多轮 RAG。\n",
    "- 明确的调用规范（参数名、变量定义、模块白名单）降低调用错误，提升可重复性与安全性。\n",
    "- 扩展性好：添加/替换工具即可扩展能力，主逻辑无需重写。\n",
    "### 缺点\n",
    "- Prompt 体积大、指令冗长，占用上下文并增加生成时延，相比直接 toolcall 成本更高。\n",
    "- 控制粒度不及手写状态机，精确流式或严格路径需额外封装。\n",
    "- 依赖工具实现与输出结构；非结构化结果仍需手动清洗，工具安全需自管。\n",
    "- 简单任务时，完整 Thought/Code/Observation 纪律会带来不必要的步骤和延迟。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8c27f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
