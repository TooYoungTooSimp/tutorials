{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ba230c",
   "metadata": {},
   "source": [
    "# Easy Agent Tutorial\n",
    "This notebook file provide three examples of using LLM based agents with different tool sets.\n",
    "\n",
    "prequisites:\n",
    "- Python 3.10+\n",
    "- Install required packages:\n",
    "  ```bash\n",
    "  pip install -r \"mcp[cli]\" smolagent\n",
    "  ```\n",
    "\n",
    "## Task Description\n",
    "\n",
    "如README所述，该项目应用三种方案，从不同的角度实现了agentic RAG的功能。为了演示，这一次我们将会构建一个信安四大会的查询，来进行感兴趣论文的搜索以及基于题目选择合适的会议进行投稿。\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a91a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们将使用dblp数据集来进行演示。首先下载四大会最近几年的会议论文数据：\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"dblp_sec_papers.json\"):\n",
    "    with requests.Session() as sess:\n",
    "        url = \"https://dblp.org/search/publ/api\"\n",
    "        params = {\"q\": \"security\", \"format\": \"json\"}\n",
    "        tocs = {\n",
    "            \"ndss\": \"toc:db/conf/ndss/ndss2025.bht:\",\n",
    "            \"sp\": \"toc:db/conf/sp/sp2025.bht:\",\n",
    "            \"ccs\": \"toc:db/conf/ccs/ccs2025.bht:\",\n",
    "            \"usenix\": \"toc:db/conf/uss/uss2025.bht:\",\n",
    "        }\n",
    "        papers = []\n",
    "        for k, v in tocs.items():\n",
    "            response = sess.get(url, params={\"q\": v, \"h\": 1000, \"format\": \"json\"})\n",
    "            data = response.json()\n",
    "            data = data[\"result\"][\"hits\"][\"hit\"]\n",
    "            papers.extend(data)\n",
    "        with open(f\"dblp_sec_papers.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "else:\n",
    "    with open(f\"dblp_sec_papers.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        papers = json.load(f)\n",
    "papers = [x[\"info\"] for x in papers]\n",
    "titles = [f\"[{x['venue']} {x['year']}] {x['title']}\" for x in papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff07b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建并保存向量数据库\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "if \"db\" not in globals():\n",
    "    db = FAISS.from_texts(titles, OpenAIEmbeddings())\n",
    "db.save_local(\"faiss_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0352eb4d",
   "metadata": {},
   "source": [
    "在开始之前，先看一下传统的工具调用大概长啥样，有怎样的优缺点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ba0df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"kw\":\"blockchain LLM papers\"}', call_id='call_ZNk69x2z6uSxuPEyhldVmhRc', name='query_db', type='function_call', id='fc_0edcc91604d6e0a4006938e28cf5c0819282e662d761ad49ea', status='completed')]\n",
      "Keyword: blockchain LLM papers\n",
      "Searching for keyword: blockchain\n",
      "Searching for keyword: LLM\n",
      "Searching for keyword: papers\n",
      "kw='blockchain LLM papers' appended.\n",
      "你这个方向目前还比较前沿，严格意义上“区块链 × LLM”的论文不算多，但已经有几类比较典型的结合方式，可以按“区块链为LLM赋能”和“LLM为区块链赋能”来找文献。我先列代表性论文和关键词，方便你自己去搜（Google Scholar / arXiv / dblp），再给你一个按方向分类的阅读建议。\n",
      "\n",
      "下面所有英文标题你直接复制去搜索就能找到 PDF。\n",
      "\n",
      "---\n",
      "\n",
      "## 一、LLM 为区块链赋能（用 LLM 做智能合约/链上安全/分析）\n",
      "\n",
      "### 1. 智能合约分析与形式化验证\n",
      "\n",
      "- **PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation**  \n",
      "  NDSS 2025（网络与分布式系统安全研讨会）  \n",
      "  关键词：  \n",
      "  - “LLM-driven Formal Verification of Smart Contracts”  \n",
      "  - “Retrieval-Augmented Property Generation”  \n",
      "  核心思路：用 LLM 自动生成合约的安全属性 / 规范，再结合形式化验证工具检查。适合关注“LLM + 智能合约安全”的同学。\n",
      "\n",
      "- 可一并检索的关键词：  \n",
      "  - “LLM for smart contract auditing”  \n",
      "  - “LLM-based smart contract vulnerability detection”  \n",
      "  - “GPT-4 for smart contract analysis”  \n",
      "\n",
      "很多不是顶会论文，而是 arXiv / 工程论文，但实用性强。\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 区块链安全、交易/地址分析\n",
      "\n",
      "- **Towards Explainable and Effective Anti-Money Laundering for Cryptocurrency**  \n",
      "  CCS 2025（计算机与通信安全大会）  \n",
      "  虽然标题没直接写 LLM，但工作里会用到深度学习/自然语言特征做可解释反洗钱；你可以配合以下关键词找更直接用 LLM 的：\n",
      "\n",
      "  推荐额外检索：\n",
      "  - “LLM for cryptocurrency transaction analysis”  \n",
      "  - “LLM-based blockchain address classification”  \n",
      "  - “LLM for DeFi risk analysis”\n",
      "\n",
      "- **Ghost Clusters: Evaluating Attribution of Illicit Services through Cryptocurrency Tracing**  \n",
      "  USENIX Security 2025  \n",
      "  主体是链上追踪和聚类，但你可以把它当成数据集/方法基础，再看后续有没有工作用 LLM 做实体归属、标签生成。\n",
      "\n",
      "---\n",
      "\n",
      "### 3. LLM 辅助 Web3/合约开发生命周期\n",
      "\n",
      "这些大多是 2023–2025 的 arXiv/Workshop 论文，可以用关键词搜：\n",
      "\n",
      "- “RAG for smart contract development”  \n",
      "- “LLM-powered Web3 development assistant”  \n",
      "- “LLM-based DeFi protocol analysis”\n",
      "\n",
      "可以重点找几个典型的：\n",
      "- “Using ChatGPT/GPT-4 for smart contract development: empirical study”\n",
      "- “LLM-based assistant for Solidity debugging”\n",
      "\n",
      "---\n",
      "\n",
      "## 二、区块链为 LLM 赋能（用区块链做 LLM 的激励/溯源/对齐）\n",
      "\n",
      "目前主流会议里“真正把 LLM 和链耦合在协议里”的工作还比较少，多数在 arXiv / 行业白皮书，典型方向包括：\n",
      "\n",
      "### 1. 模型溯源、版权与水印登记\n",
      "\n",
      "关键词可以这样搜：\n",
      "\n",
      "- “blockchain-based provenance for LLM outputs”  \n",
      "- “on-chain provenance for AI-generated content”  \n",
      "- “blockchain watermarking LLM text”  \n",
      "\n",
      "可以和这类论文一起看（虽然不一定都上链，但概念相近）：\n",
      "- **Provably Robust Multi-bit Watermarking for AI-generated Text**  \n",
      "  NDSS 2025  \n",
      "  再结合 “blockchain for robust watermark registry” 会有一些后续工作。\n",
      "\n",
      "### 2. 分布式/去中心化 LLM 训练与推理激励\n",
      "\n",
      "典型关键词（很多是 arXiv / 项目白皮书）：\n",
      "- “decentralized training of LLM with blockchain incentives”  \n",
      "- “token-incentivized LLM inference marketplace”  \n",
      "- “blockchain-based federated learning for LLM”  \n",
      "\n",
      "可以找类似：\n",
      "- “Bittensor: A Peer-to-Peer Market for Machine Intelligence”（项目白皮书/论文，典型“区块链 + 模型市场”）\n",
      "- “Gensyn” / “Akash AI” 等会有分布式算力+AI 的论文/白皮书\n",
      "\n",
      "---\n",
      "\n",
      "## 三、“安全视角”下的区块链 × LLM（安全圈目前最活跃）\n",
      "\n",
      "这些不是“在协议层面紧密耦合”的区块链+LLM，但对你理解安全问题很有帮助：\n",
      "\n",
      "### 1. LLM 帮你搞区块链安全\n",
      "\n",
      "- **YuraScanner: Leveraging LLMs for Task-driven Web App Scanning**  \n",
      "  NDSS 2025  \n",
      "  侧重点是 Web 安全扫描，但方法可以迁移到 Web3 前端 / 钱包 DApp 安全扫描。\n",
      "\n",
      "- “LLM-based fuzzing for smart contracts”  \n",
      "  可以和下面这篇一起看思路：  \n",
      "  - **Hybrid Language Processor Fuzzing via LLM-Based Constraint Solving**  \n",
      "    USENIX Security 2025  \n",
      "\n",
      "### 2. 区块链场景中的 LLM 风险（间接交叉）\n",
      "\n",
      "当你用 LLM 去构建 Web3 应用时，这类论文里讲的攻击/防御很关键：\n",
      "\n",
      "- **When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs**  \n",
      "  USENIX Security 2025  \n",
      "  适用于 “有钱包 / 区块链读写能力的 Agent” 场景安全分析。\n",
      "\n",
      "- **On the (In)Security of LLM App Stores** – S&P 2025  \n",
      "  如果你构建“插件化的 Web3 Agent 商店”，这里的威胁模型可以直接借用。\n",
      "\n",
      "- 一些对 LLM 越狱、安全性、隐私的论文：  \n",
      "  - SelfDefend, PAPILLON, Activation Approximations…, PrivacyXray, Private Investigator, TracLLM 等（USENIX / NDSS / S&P 2025）  \n",
      "  在设计“链上 Agent DAO”“自治交易机器人”时，LLM 的安全问题会直接映射成资金风险。\n",
      "\n",
      "---\n",
      "\n",
      "## 四、给你一个检索策略（方便你扩展）\n",
      "\n",
      "你可以这样在 Google Scholar / arXiv 搜：\n",
      "\n",
      "1. 直接搜组合关键词：\n",
      "   - `\"blockchain\" \"large language model\"`  \n",
      "   - `\"web3\" \"large language model\"`  \n",
      "   - `\"smart contract\" \"large language model\"`  \n",
      "   - `\"DeFi\" \"large language model\"`  \n",
      "\n",
      "2. 指定近两年时间：\n",
      "   - Google Scholar 左侧 “Since 2023 / 2024 / 2025”\n",
      "\n",
      "3. 结合你关心的子方向：\n",
      "   - 安全：`\"LLM\" \"smart contract security\"` / `\"LLM\" \"DeFi risk\"`  \n",
      "   - 激励与协议：`\"LLM marketplace\" \"blockchain\"`  \n",
      "   - 隐私与合规：`\"on-chain provenance\" \"LLM\"` / `\"GDPR\" \"LLM\" \"blockchain\"`\n",
      "\n",
      "---\n",
      "\n",
      "## 五、如果你告诉我更细的兴趣，我可以给你“精读清单”\n",
      "\n",
      "比如你更偏向：\n",
      "\n",
      "- 做“LLM 辅助智能合约审计/验证”  \n",
      "- 做“去中心化 LLM / 模型市场 / Agent DAO 协议设计”  \n",
      "- 或者“用区块链做 LLM 输出的溯源、版权和监管”\n",
      "\n",
      "你说一下具体方向，我可以帮你整理一个更窄的 5–10 篇“必读 + 可选”列表，并按阅读顺序、重点 section 给你标出来。\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import re\n",
    "\n",
    "import dotenv\n",
    "import tenacity\n",
    "import yaml\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "from openai.types import *\n",
    "from openai.types.chat import *\n",
    "\n",
    "\n",
    "def raw_toolcall():\n",
    "    client = OpenAI()\n",
    "    db = FAISS.load_local(\n",
    "        \"faiss_db\",\n",
    "        OpenAIEmbeddings(),\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "    tools_def = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"name\": \"query_db\",\n",
    "            \"description\": \"accept keyword and return related information\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"kw\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The keyword to query the database\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"kw\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    def real_ask(question: str):\n",
    "        from openai.types.responses.response_input_param import Message\n",
    "\n",
    "        input_msgs: list[Message] = [\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are a helpful research assistant. When given a question, you must first decide if you need to query the database to get relevant information. If so, use the tool 'query_db' with appropriate keywords extracted from the question. After getting the information, provide a comprehensive answer based on both the retrieved information and your own knowledge.\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            },\n",
    "        ]\n",
    "        resp = client.responses.create(\n",
    "            model=\"gpt-5.1\",\n",
    "            tools=tools_def,\n",
    "            input=input_msgs,\n",
    "            tool_choice=\"required\",\n",
    "        )\n",
    "        print(resp.output)\n",
    "        for toolcall in resp.output:\n",
    "            if toolcall.type != \"function_call\":\n",
    "                continue\n",
    "            if toolcall.name == \"query_db\":\n",
    "                kw = json.loads(toolcall.arguments)[\"kw\"]\n",
    "                print(f\"Keyword: {kw}\")\n",
    "                docs = []\n",
    "                for skw in kw.split():\n",
    "                    if not (skw := skw.strip()):\n",
    "                        continue\n",
    "                    print(f\"Searching for keyword: {skw}\")\n",
    "                    docs.extend(db.similarity_search(skw, k=30))\n",
    "                rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "                input_msgs.append(toolcall)\n",
    "                input_msgs.append(\n",
    "                    {\n",
    "                        \"type\": \"function_call_output\",\n",
    "                        \"call_id\": toolcall.call_id,\n",
    "                        \"output\": str(rag_result),\n",
    "                    }\n",
    "                )\n",
    "                print(f\"{kw=} appended.\")\n",
    "        if input_msgs[-1][\"type\"] == \"function_call_output\":\n",
    "            resp = client.responses.create(\n",
    "                model=\"gpt-5.1\",\n",
    "                input=input_msgs,\n",
    "                # tools=tools_def,\n",
    "                stream=True,\n",
    "            )\n",
    "            for chunk in resp:\n",
    "                if chunk.type == \"response.output_text.delta\":\n",
    "                    print(chunk.delta, end=\"\", flush=True)\n",
    "            print()\n",
    "        else:\n",
    "            print(resp.output_text)\n",
    "\n",
    "    while True:\n",
    "        inp = input(\"=> \")\n",
    "        if not inp.strip():\n",
    "            break\n",
    "        real_ask(inp)\n",
    "\n",
    "\n",
    "raw_toolcall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0f2b1",
   "metadata": {},
   "source": [
    "### 传统工具调用的优缺点\n",
    "\n",
    "- 优点：直接用模型原生的 function/tool 调用协议，链路短、开销低，JSON Schema 参数校验清晰。\n",
    "- 优点：可以精确控制何时调用工具、使用 `tool_choice` 等参数强制执行，消息格式透明、便于调试和流式输出。\n",
    "- 优点：依赖少，不绑框架，易于插入到现有服务或与其他编排层组合。\n",
    "- 缺点：需要手写对话状态管理、工具输入输出拼接，容易出错且样板代码多。\n",
    "- 缺点：缺少自动规划/多步推理、重试、fallback 等封装能力，复杂流程要自行实现。\n",
    "- 缺点：与特定模型/协议耦合，换提供方或多模型时需适配；安全性与数据清洗（如反序列化、去重）也要自管。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888af19",
   "metadata": {},
   "source": [
    "## SmolAgent::CodeAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d330b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You are a helpful research assistant. When given a question, you must first decide if you need to query the </span>    <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">database to get relevant information. If so, use the tool 'query_db' with appropriate keywords extracted from </span>  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">the question. After getting the information, provide a comprehensive answer based on both the retrieved </span>        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">information and your own knowledge.</span>                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">精选几篇llm安全的论文</span>                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIModel - gpt-5.1 ─────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou are a helpful research assistant. When given a question, you must first decide if you need to query the \u001b[0m    \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mdatabase to get relevant information. If so, use the tool 'query_db' with appropriate keywords extracted from \u001b[0m  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mthe question. After getting the information, provide a comprehensive answer based on both the retrieved \u001b[0m        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1minformation and your own knowledge.\u001b[0m                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m精选几篇llm安全的论文\u001b[0m                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIModel - gpt-5.1 \u001b[0m\u001b[38;2;212;183;2m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f2a10965334674a8125aedd0755d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Thought:</span><span style=\"background-color: #272822\">                                                                                                     </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The user asks (in Chinese) to \"select a few LLM safety papers\".</span><span style=\"background-color: #272822\">                                              </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># I should query the database using keywords like \"LLM safety\", \"AI alignment\", \"AI safety\", etc.,</span><span style=\"background-color: #272822\">             </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># then use my own knowledge plus the returned titles to recommend and briefly describe several key papers.</span><span style=\"background-color: #272822\">     </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Step 1: query the DB for relevant titles.</span><span style=\"background-color: #272822\">                                                                    </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">kw </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"large language model safety alignment robustness red teaming RLHF\"</span><span style=\"background-color: #272822\">                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">titles </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> query_db(kw</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">kw)</span><span style=\"background-color: #272822\">                                                                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(titles)</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Thought:\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# The user asks (in Chinese) to \"select a few LLM safety papers\".\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# I should query the database using keywords like \"LLM safety\", \"AI alignment\", \"AI safety\", etc.,\u001b[0m\u001b[48;2;39;40;34m             \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# then use my own knowledge plus the returned titles to recommend and briefly describe several key papers.\u001b[0m\u001b[48;2;39;40;34m     \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Step 1: query the DB for relevant titles.\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mkw\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mlarge language model safety alignment robustness red teaming RLHF\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mtitles\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery_db\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkw\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkw\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtitles\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for keyword: large\n",
      "Searching for keyword: language\n",
      "Searching for keyword: language\n",
      "Searching for keyword: model\n",
      "Searching for keyword: model\n",
      "Searching for keyword: safety\n",
      "Searching for keyword: safety\n",
      "Searching for keyword: alignment\n",
      "Searching for keyword: alignment\n",
      "Searching for keyword: robustness\n",
      "Searching for keyword: robustness\n",
      "Searching for keyword: red\n",
      "Searching for keyword: red\n",
      "Searching for keyword: teaming\n",
      "Searching for keyword: teaming\n",
      "Searching for keyword: RLHF\n",
      "Searching for keyword: RLHF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[NDSS 2025] From Large to Mammoth: A Comparative Evaluation of Large Language Models in Vulnerability Detection.\n",
       "[USENIX Security Symposium 2025] Preventing Artificially Inflated SMS Attacks through Large-Scale Traffic \n",
       "Inspection.\n",
       "[USENIX Security Symposium 2025] IRBlock: A Large-Scale Measurement Study of the Great Firewall of Iran.\n",
       "[USENIX Security Symposium 2025] When Translators Refuse to Translate: A Novel Attack to Speech Translation \n",
       "Systems.\n",
       "[USENIX Security Symposium 2025] Tracking the Takes and Trajectories of English-Language News Narratives across \n",
       "Trustworthy and Worrisome Websites.\n",
       "[SP 2025] PyLingual: Toward Perfect Decompilation of Evolving High-Level Languages.\n",
       "[NDSS 2025] The Philosopher&amp;apos;s Stone: Trojaning Plugins of Large Language Models.\n",
       "[USENIX Security Symposium 2025] JBShield: Defending Large Language Models from Jailbreak Attacks through Activated\n",
       "Concept Analysis and Manipulation.\n",
       "[USENIX Security Symposium 2025] From Purity to Peril: Backdooring Merged Models From &amp;quot;Harmless&amp;quot; Benign \n",
       "Components.\n",
       "[USENIX Security Symposium 2025] Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models.\n",
       "[CCS 2025] YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models.\n",
       "[USENIX Security Symposium 2025] Investigating the Impact of Online Community Involvement on Safety Practices and \n",
       "Perceived Risks Among People Who Use Drugs.\n",
       "[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\n",
       "[USENIX Security Symposium 2025] TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts.\n",
       "[CCS 2025] SecAlign: Defending Against Prompt Injection with Preference Optimization.\n",
       "[USENIX Security Symposium 2025] SoK: Efficiency Robustness of Dynamic Deep Learning Systems.\n",
       "[CCS 2025] Exact Robustness Certification of k-Nearest Neighbors.\n",
       "[USENIX Security Symposium 2025] Watch the Watchers! On the Security Risks of Robustness-Enhancing Diffusion \n",
       "Models.\n",
       "[USENIX Security Symposium 2025] Red Bleed: A Pragmatic Near-Infrared Presentation Attack on Facial Biometric \n",
       "Authentication Systems.\n",
       "[USENIX Security Symposium 2025] BLuEMan: A Stateful Simulation-based Fuzzing Framework for Open-Source RTOS \n",
       "Bluetooth Low Energy Protocol Stacks.\n",
       "[USENIX Security Symposium 2025] From Alarms to Real Bugs: Multi-target Multi-step Directed Greybox Fuzzing for \n",
       "Static Analysis Result Verification.\n",
       "[CCS 2025] GPU Travelling: Efficient Confidential Collaborative Training with TEE-Enabled GPUs.\n",
       "[NDSS 2025] The Forking Way: When TEEs Meet Consensus.\n",
       "[USENIX Security Symposium 2025] Phantom: Privacy-Preserving Deep Neural Network Model Obfuscation in Heterogeneous\n",
       "TEE and GPU System.\n",
       "[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones\n",
       "with mmWave Radar.\n",
       "[USENIX Security Symposium 2025] LLFuzz: An Over-the-Air Dynamic Testing Framework for Cellular Baseband Lower \n",
       "Layers.\n",
       "[SP 2025] Lombard-VLD: Voice Liveness Detection Based on Human Auditory Feedback.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[NDSS 2025] From Large to Mammoth: A Comparative Evaluation of Large Language Models in Vulnerability Detection.\n",
       "[USENIX Security Symposium 2025] Preventing Artificially Inflated SMS Attacks through Large-Scale Traffic \n",
       "Inspection.\n",
       "[USENIX Security Symposium 2025] IRBlock: A Large-Scale Measurement Study of the Great Firewall of Iran.\n",
       "[USENIX Security Symposium 2025] When Translators Refuse to Translate: A Novel Attack to Speech Translation \n",
       "Systems.\n",
       "[USENIX Security Symposium 2025] Tracking the Takes and Trajectories of English-Language News Narratives across \n",
       "Trustworthy and Worrisome Websites.\n",
       "[SP 2025] PyLingual: Toward Perfect Decompilation of Evolving High-Level Languages.\n",
       "[NDSS 2025] The Philosopher&apos;s Stone: Trojaning Plugins of Large Language Models.\n",
       "[USENIX Security Symposium 2025] JBShield: Defending Large Language Models from Jailbreak Attacks through Activated\n",
       "Concept Analysis and Manipulation.\n",
       "[USENIX Security Symposium 2025] From Purity to Peril: Backdooring Merged Models From &quot;Harmless&quot; Benign \n",
       "Components.\n",
       "[USENIX Security Symposium 2025] Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models.\n",
       "[CCS 2025] YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models.\n",
       "[USENIX Security Symposium 2025] Investigating the Impact of Online Community Involvement on Safety Practices and \n",
       "Perceived Risks Among People Who Use Drugs.\n",
       "[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\n",
       "[USENIX Security Symposium 2025] TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts.\n",
       "[CCS 2025] SecAlign: Defending Against Prompt Injection with Preference Optimization.\n",
       "[USENIX Security Symposium 2025] SoK: Efficiency Robustness of Dynamic Deep Learning Systems.\n",
       "[CCS 2025] Exact Robustness Certification of k-Nearest Neighbors.\n",
       "[USENIX Security Symposium 2025] Watch the Watchers! On the Security Risks of Robustness-Enhancing Diffusion \n",
       "Models.\n",
       "[USENIX Security Symposium 2025] Red Bleed: A Pragmatic Near-Infrared Presentation Attack on Facial Biometric \n",
       "Authentication Systems.\n",
       "[USENIX Security Symposium 2025] BLuEMan: A Stateful Simulation-based Fuzzing Framework for Open-Source RTOS \n",
       "Bluetooth Low Energy Protocol Stacks.\n",
       "[USENIX Security Symposium 2025] From Alarms to Real Bugs: Multi-target Multi-step Directed Greybox Fuzzing for \n",
       "Static Analysis Result Verification.\n",
       "[CCS 2025] GPU Travelling: Efficient Confidential Collaborative Training with TEE-Enabled GPUs.\n",
       "[NDSS 2025] The Forking Way: When TEEs Meet Consensus.\n",
       "[USENIX Security Symposium 2025] Phantom: Privacy-Preserving Deep Neural Network Model Obfuscation in Heterogeneous\n",
       "TEE and GPU System.\n",
       "[USENIX Security Symposium 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones\n",
       "with mmWave Radar.\n",
       "[USENIX Security Symposium 2025] LLFuzz: An Over-the-Air Dynamic Testing Framework for Cellular Baseband Lower \n",
       "Layers.\n",
       "[SP 2025] Lombard-VLD: Voice Liveness Detection Based on Human Auditory Feedback.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 31.35 seconds| Input tokens: 2,078 | Output tokens: 2,008]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 31.35 seconds| Input tokens: 2,078 | Output tokens: 2,008]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1024657ff344d6188ffde12d5a127f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> final_answer </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> final_answer</span><span style=\"background-color: #272822\">                                                                          </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># 根据你给的执行日志人工筛选，和 LLM 安全直接相关的论文主要有：</span><span style=\"background-color: #272822\">                                                </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">selected </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> [</span><span style=\"background-color: #272822\">                                                                                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security 2025] JBShield: Defending Large Language Models from Jailbreak Attacks through Activated </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Concept Analysis and Manipulation.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security 2025] From Purity to Peril: Backdooring Merged Models From </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">\\\"</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Harmless</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">\\\"</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\"> Benign </span><span style=\"background-color: #272822\">          </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Components.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security 2025] Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security 2025] TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[CCS 2025] SecAlign: Defending Against Prompt Injection with Preference Optimization.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[NDSS 2025] The Philosopher's Stone: Trojaning Plugins of Large Language Models.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                        </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"[USENIX Security 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">with mmWave Radar.\"</span><span style=\"background-color: #272822\">                                                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                                                              </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">summary </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">f\"\"\"我从你给出的 NDSS / Oakland (SP) / USENIX Security / CCS 2025 </span><span style=\"background-color: #272822\">                                   </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">论文列表里，挑出几篇和“大语言模型安全”直接相关、很值得关注的工作，按主题简单分组，方便你做调研或写 </span><span style=\"background-color: #272822\">            </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">survey。下面都是你日志里已经出现的论文，并结合题目+常见研究方向做简要解读。</span><span style=\"background-color: #272822\">                                    </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 一、越狱攻击与越狱防御（Jailbreak &amp; Prompt 攻击）</span><span style=\"background-color: #272822\">                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 1. JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Manipulation  </span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：越狱防御、内部激活/概念分析、安全对齐保持。  </span><span style=\"background-color: #272822\">                                                      </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 利用“激活概念分析”（activated concept </span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">analysis）来理解模型内部表征哪些“危险概念”（如暴力、仇恨等），在检测到这些概念被触发时进行抑制或重写，从而阻止</span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">越狱提示成功。</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 属于“模型内部机制层面”的防御，而不仅是简单规则过滤。  </span><span style=\"background-color: #272822\">                                                       </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 越狱防御是 LLM 安全的核心问题之一，这篇代表了一种“从内部表征出发”的防御路线，可以和基于 RLHF / </span><span style=\"background-color: #272822\">              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">审查规则的办法做对比。</span><span style=\"background-color: #272822\">                                                                                         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 2. TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts  </span><span style=\"background-color: #272822\">                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：越狱攻击、提示结构设计、对齐绕过。  </span><span style=\"background-color: #272822\">                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 提出一种“Twin </span><span style=\"background-color: #272822\">                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Prompts（双提示）”结构，通过构造两段关联提示，让模型在遵守一段指令的同时无意间违反另一段更高层次的安全对齐约束</span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">。</span><span style=\"background-color: #272822\">                                                                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 系统化研究这种结构是否对主流对齐策略（RLHF、system prompt 等）具有普适威力。  </span><span style=\"background-color: #272822\">                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 如果你在研究越狱攻击方法，这篇可能给出了一套新的攻击范式与评测基准。  </span><span style=\"background-color: #272822\">                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 也可作为防御方理解攻击模式的素材。</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 3. SecAlign: Defending Against Prompt Injection with Preference Optimization  </span><span style=\"background-color: #272822\">                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：CCS 2025  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：Prompt Injection、对齐、防御、偏好优化。  </span><span style=\"background-color: #272822\">                                                         </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 把“对抗 Prompt </span><span style=\"background-color: #272822\">                                                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Injection”转化为一个偏好优化问题：模型应该偏好遵守系统指令/有权限的指令，而拒绝遵守外部恶意指令。</span><span style=\"background-color: #272822\">              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 可能基于 DPO、IPO 或 RLHF 类方法，在训练中加入“安全偏好对比数据”（遵守合法提示 vs 遵守注入提示）。  </span><span style=\"background-color: #272822\">         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- Prompt Injection 是 </span><span style=\"background-color: #272822\">                                                                                         </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">LLM+工具/LLM+检索系统中的关键威胁，这篇直接从“对齐训练”的视角给出防御方案，非常贴合实际应用场景。  </span><span style=\"background-color: #272822\">            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 二、安全对齐与微调阶段的对齐保持</span><span style=\"background-color: #272822\">                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 4. Alleviating the Fear of Losing Alignment in LLM Fine-tuning  </span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：IEEE S&amp;P (Oakland/SP) 2025  </span><span style=\"background-color: #272822\">                                                                         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：对齐保持、微调安全、后训练对齐退化。  </span><span style=\"background-color: #272822\">                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 研究在 SFT/LoRA/任务微调时，如何避免已有的安全对齐能力“被覆盖”或“被遗忘”（alignment forgetting）。</span><span style=\"background-color: #272822\">           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 可能提出新的正则化、参数隔离或对齐约束技术，让模型在适应新任务时仍保持安全属性。  </span><span style=\"background-color: #272822\">                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- </span><span style=\"background-color: #272822\">                                                                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">现实中企业/研究者经常在基础模型上做二次微调，这篇很切实际地解决“微调会不会把安全对齐搞丢”的问题，是工程落地时必</span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">读的方向。</span><span style=\"background-color: #272822\">                                                                                                     </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 5. Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models  </span><span style=\"background-color: #272822\">                        </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：对齐反转、unlearning、安全绕过。  </span><span style=\"background-color: #272822\">                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- “反向”问题：证明或者展示可以通过某些训练/攻击手段，让模型逐步“忘掉”其安全对齐能力，使其变得更易输出有害内容。</span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 可能结合参数编辑、对抗微调或持续学习来研究“对齐可逆性”和“安全不可逆性”的界限。  </span><span style=\"background-color: #272822\">                             </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 从攻防两侧都极有价值：  </span><span style=\"background-color: #272822\">                                                                                     </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - 攻击者视角：说明现有对齐是否能够被系统性卸除。  </span><span style=\"background-color: #272822\">                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - 防御者与治理视角：促使提出“难以反对齐”的机制，比如结构性约束或不可逆安全模块。</span><span style=\"background-color: #272822\">                             </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 三、后门 / 插件 / 生态层面的 LLM 威胁</span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 6. From Purity to Peril: Backdooring Merged Models From \"Harmless\" Benign Components  </span><span style=\"background-color: #272822\">                     </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：模型合并、后门、权重组合、开源模型。  </span><span style=\"background-color: #272822\">                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 研究当我们用“模型合并”（merge </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">models、模型融合）技术时，即便每个单独模型看来是“干净”的，也可能在合并后激发潜在后门或隐藏行为。</span><span style=\"background-color: #272822\">               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 对开源 LLM 社区非常现实：当前大量模型是通过 merge/checkpoint mixing 得来。  </span><span style=\"background-color: #272822\">                                 </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 如果你关注 LLM 供应链安全 / 开源模型生态，这篇非常关键。  </span><span style=\"background-color: #272822\">                                                   </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 提醒大家：安全属性在模型合并时不是简单线性叠加，可能出现新的脆弱性。</span><span style=\"background-color: #272822\">                                         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 7. The Philosopher's Stone: Trojaning Plugins of Large Language Models  </span><span style=\"background-color: #272822\">                                   </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：NDSS 2025  </span><span style=\"background-color: #272822\">                                                                                          </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：插件、工具调用、Trojan/后门、生态攻击。  </span><span style=\"background-color: #272822\">                                                          </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 针对 LLM </span><span style=\"background-color: #272822\">                                                                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">的“插件/工具”系统，研究如何在插件层面植入后门（例如特定输入触发危险行为或数据泄露），而基础模型本身看起来仍然“</span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">安全对齐”。</span><span style=\"background-color: #272822\">                                                                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 分析 LLM+工具生态中的信任边界、权限模型和 Trojan 注入面。  </span><span style=\"background-color: #272822\">                                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 随着 LLM Agent / tool-using LLM 成为主流，这篇几乎是必读的“插件层安全”论文，有助于你构建系统级安全威胁模型。</span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 四、评测与特殊人群安全（Youth Safety）</span><span style=\"background-color: #272822\">                                                                      </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 8. YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models  </span><span style=\"background-color: #272822\">             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：CCS 2025  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：青少年安全、内容审核、基准测试、安全护栏。  </span><span style=\"background-color: #272822\">                                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 从“青少年用户”的视角，定义适宜/不适宜内容标准，构建一个针对 LLM 的安全 benchmark（题目、对话场景等）。</span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 可能同时训练一个专门的“Safeguard Model”，作为过滤或协同审查模块，保护未成年人免受不良内容影响。  </span><span style=\"background-color: #272822\">            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- LLM 在教育、陪伴等领域的应用越来越多，未成年人保护是监管和产品落地的核心问题。  </span><span style=\"background-color: #272822\">                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 这篇可以给你一个“用户群体敏感维度”的安全评测思路，而不仅是通用 NSFW/violence/hate 分类。</span><span style=\"background-color: #272822\">                     </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 五、LLM 作为攻击增强器的安全研究</span><span style=\"background-color: #272822\">                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 9. EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar  </span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：侧信道攻击、声学窃听、LLM-augmented。  </span><span style=\"background-color: #272822\">                                                            </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 通过 mmWave 雷达探测骨传导耳机的物理信号，再用 LLM 进行语音内容/语义恢复或文本推断，从而实现窃听攻击。</span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- LLM 在这里作为“增强解码与语义理解”的组件。  </span><span style=\"background-color: #272822\">                                                                 </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 代表一大类趋势：**LLM 作为攻击增强器**，不是攻击对象本身，而是提升攻击链路中的推理/识别能力。  </span><span style=\"background-color: #272822\">              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 如果你关心“LLM + 传统安全攻击”的结合，这是一个很好的案例。</span><span style=\"background-color: #272822\">                                                   </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 六、如何利用这份“精选列表”</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">如果你要写一篇关于 **LLM 安全/攻防的综述**，可以大致按以下结构阅读和组织：</span><span style=\"background-color: #272822\">                                     </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">1. **对齐与微调阶段安全**  </span><span style=\"background-color: #272822\">                                                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *Alleviating the Fear of Losing Alignment in LLM Fine-tuning*  </span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *Refusal Is Not an Option: Unlearning Safety Alignment of LLMs*</span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">2. **越狱与 Prompt 攻击/防御**  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *JBShield*  </span><span style=\"background-color: #272822\">                                                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *TwinBreak*  </span><span style=\"background-color: #272822\">                                                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *SecAlign*</span><span style=\"background-color: #272822\">                                                                                                </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">3. **供应链与生态安全（模型合并、插件、工具）**  </span><span style=\"background-color: #272822\">                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *From Purity to Peril: Backdooring Merged Models...*  </span><span style=\"background-color: #272822\">                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *The Philosopher's Stone: Trojaning Plugins of LLMs*</span><span style=\"background-color: #272822\">                                                      </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">4. **特定用户群与内容安全评测**  </span><span style=\"background-color: #272822\">                                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *YouthSafe*</span><span style=\"background-color: #272822\">                                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">5. **LLM 赋能的攻击场景**  </span><span style=\"background-color: #272822\">                                                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *EchoLLM*</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">如果你愿意，我可以在下一步帮你：  </span><span style=\"background-color: #272822\">                                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 按上述结构写一个更正式的 survey 大纲（包括可能的 related work 分类、问题定义、open problems）；  </span><span style=\"background-color: #272822\">            </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 或者为其中任意一篇草拟中文阅读笔记/导读，帮助快速进入论文细节。</span><span style=\"background-color: #272822\">                                              </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(summary)</span><span style=\"background-color: #272822\">                                                                                          </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# 根据你给的执行日志人工筛选，和 LLM 安全直接相关的论文主要有：\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mselected\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security 2025] JBShield: Defending Large Language Models from Jailbreak Attacks through Activated \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mConcept Analysis and Manipulation.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security 2025] From Purity to Peril: Backdooring Merged Models From \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m\\\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mHarmless\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m\\\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m Benign \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mComponents.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security 2025] Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[SP 2025] Alleviating the Fear of Losing Alignment in LLM Fine-tuning.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security 2025] TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[CCS 2025] SecAlign: Defending Against Prompt Injection with Preference Optimization.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[NDSS 2025] The Philosopher\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms Stone: Trojaning Plugins of Large Language Models.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[USENIX Security 2025] EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mwith mmWave Radar.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34msummary\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mf\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m我从你给出的 NDSS / Oakland (SP) / USENIX Security / CCS 2025 \u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m论文列表里，挑出几篇和“大语言模型安全”直接相关、很值得关注的工作，按主题简单分组，方便你做调研或写 \u001b[0m\u001b[48;2;39;40;34m            \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34msurvey。下面都是你日志里已经出现的论文，并结合题目+常见研究方向做简要解读。\u001b[0m\u001b[48;2;39;40;34m                                    \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 一、越狱攻击与越狱防御（Jailbreak & Prompt 攻击）\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 1. JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mManipulation  \u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：越狱防御、内部激活/概念分析、安全对齐保持。  \u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 利用“激活概念分析”（activated concept \u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34manalysis）来理解模型内部表征哪些“危险概念”（如暴力、仇恨等），在检测到这些概念被触发时进行抑制或重写，从而阻止\u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m越狱提示成功。\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 属于“模型内部机制层面”的防御，而不仅是简单规则过滤。  \u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 越狱防御是 LLM 安全的核心问题之一，这篇代表了一种“从内部表征出发”的防御路线，可以和基于 RLHF / \u001b[0m\u001b[48;2;39;40;34m              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m审查规则的办法做对比。\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 2. TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts  \u001b[0m\u001b[48;2;39;40;34m                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：越狱攻击、提示结构设计、对齐绕过。  \u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 提出一种“Twin \u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mPrompts（双提示）”结构，通过构造两段关联提示，让模型在遵守一段指令的同时无意间违反另一段更高层次的安全对齐约束\u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m。\u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 系统化研究这种结构是否对主流对齐策略（RLHF、system prompt 等）具有普适威力。  \u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 如果你在研究越狱攻击方法，这篇可能给出了一套新的攻击范式与评测基准。  \u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 也可作为防御方理解攻击模式的素材。\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 3. SecAlign: Defending Against Prompt Injection with Preference Optimization  \u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：CCS 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：Prompt Injection、对齐、防御、偏好优化。  \u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 把“对抗 Prompt \u001b[0m\u001b[48;2;39;40;34m                                                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mInjection”转化为一个偏好优化问题：模型应该偏好遵守系统指令/有权限的指令，而拒绝遵守外部恶意指令。\u001b[0m\u001b[48;2;39;40;34m              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 可能基于 DPO、IPO 或 RLHF 类方法，在训练中加入“安全偏好对比数据”（遵守合法提示 vs 遵守注入提示）。  \u001b[0m\u001b[48;2;39;40;34m         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- Prompt Injection 是 \u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mLLM+工具/LLM+检索系统中的关键威胁，这篇直接从“对齐训练”的视角给出防御方案，非常贴合实际应用场景。  \u001b[0m\u001b[48;2;39;40;34m            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 二、安全对齐与微调阶段的对齐保持\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 4. Alleviating the Fear of Losing Alignment in LLM Fine-tuning  \u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：IEEE S&P (Oakland/SP) 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：对齐保持、微调安全、后训练对齐退化。  \u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 研究在 SFT/LoRA/任务微调时，如何避免已有的安全对齐能力“被覆盖”或“被遗忘”（alignment forgetting）。\u001b[0m\u001b[48;2;39;40;34m           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 可能提出新的正则化、参数隔离或对齐约束技术，让模型在适应新任务时仍保持安全属性。  \u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m现实中企业/研究者经常在基础模型上做二次微调，这篇很切实际地解决“微调会不会把安全对齐搞丢”的问题，是工程落地时必\u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m读的方向。\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 5. Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models  \u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：对齐反转、unlearning、安全绕过。  \u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- “反向”问题：证明或者展示可以通过某些训练/攻击手段，让模型逐步“忘掉”其安全对齐能力，使其变得更易输出有害内容。\u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 可能结合参数编辑、对抗微调或持续学习来研究“对齐可逆性”和“安全不可逆性”的界限。  \u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 从攻防两侧都极有价值：  \u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m  - 攻击者视角：说明现有对齐是否能够被系统性卸除。  \u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m  - 防御者与治理视角：促使提出“难以反对齐”的机制，比如结构性约束或不可逆安全模块。\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 三、后门 / 插件 / 生态层面的 LLM 威胁\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 6. From Purity to Peril: Backdooring Merged Models From \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mHarmless\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m Benign Components  \u001b[0m\u001b[48;2;39;40;34m                     \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：模型合并、后门、权重组合、开源模型。  \u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 研究当我们用“模型合并”（merge \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mmodels、模型融合）技术时，即便每个单独模型看来是“干净”的，也可能在合并后激发潜在后门或隐藏行为。\u001b[0m\u001b[48;2;39;40;34m               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 对开源 LLM 社区非常现实：当前大量模型是通过 merge/checkpoint mixing 得来。  \u001b[0m\u001b[48;2;39;40;34m                                 \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 如果你关注 LLM 供应链安全 / 开源模型生态，这篇非常关键。  \u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 提醒大家：安全属性在模型合并时不是简单线性叠加，可能出现新的脆弱性。\u001b[0m\u001b[48;2;39;40;34m                                         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 7. The Philosopher\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms Stone: Trojaning Plugins of Large Language Models  \u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：NDSS 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：插件、工具调用、Trojan/后门、生态攻击。  \u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 针对 LLM \u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m的“插件/工具”系统，研究如何在插件层面植入后门（例如特定输入触发危险行为或数据泄露），而基础模型本身看起来仍然“\u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m安全对齐”。\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 分析 LLM+工具生态中的信任边界、权限模型和 Trojan 注入面。  \u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 随着 LLM Agent / tool-using LLM 成为主流，这篇几乎是必读的“插件层安全”论文，有助于你构建系统级安全威胁模型。\u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 四、评测与特殊人群安全（Youth Safety）\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 8. YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models  \u001b[0m\u001b[48;2;39;40;34m             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：CCS 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：青少年安全、内容审核、基准测试、安全护栏。  \u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 从“青少年用户”的视角，定义适宜/不适宜内容标准，构建一个针对 LLM 的安全 benchmark（题目、对话场景等）。\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 可能同时训练一个专门的“Safeguard Model”，作为过滤或协同审查模块，保护未成年人免受不良内容影响。  \u001b[0m\u001b[48;2;39;40;34m            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- LLM 在教育、陪伴等领域的应用越来越多，未成年人保护是监管和产品落地的核心问题。  \u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 这篇可以给你一个“用户群体敏感维度”的安全评测思路，而不仅是通用 NSFW/violence/hate 分类。\u001b[0m\u001b[48;2;39;40;34m                     \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 五、LLM 作为攻击增强器的安全研究\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 9. EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar  \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：侧信道攻击、声学窃听、LLM-augmented。  \u001b[0m\u001b[48;2;39;40;34m                                                            \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 通过 mmWave 雷达探测骨传导耳机的物理信号，再用 LLM 进行语音内容/语义恢复或文本推断，从而实现窃听攻击。\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- LLM 在这里作为“增强解码与语义理解”的组件。  \u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 代表一大类趋势：**LLM 作为攻击增强器**，不是攻击对象本身，而是提升攻击链路中的推理/识别能力。  \u001b[0m\u001b[48;2;39;40;34m              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 如果你关心“LLM + 传统安全攻击”的结合，这是一个很好的案例。\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 六、如何利用这份“精选列表”\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m如果你要写一篇关于 **LLM 安全/攻防的综述**，可以大致按以下结构阅读和组织：\u001b[0m\u001b[48;2;39;40;34m                                     \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m1. **对齐与微调阶段安全**  \u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *Alleviating the Fear of Losing Alignment in LLM Fine-tuning*  \u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *Refusal Is Not an Option: Unlearning Safety Alignment of LLMs*\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m2. **越狱与 Prompt 攻击/防御**  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *JBShield*  \u001b[0m\u001b[48;2;39;40;34m                                                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *TwinBreak*  \u001b[0m\u001b[48;2;39;40;34m                                                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *SecAlign*\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m3. **供应链与生态安全（模型合并、插件、工具）**  \u001b[0m\u001b[48;2;39;40;34m                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *From Purity to Peril: Backdooring Merged Models...*  \u001b[0m\u001b[48;2;39;40;34m                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *The Philosopher\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms Stone: Trojaning Plugins of LLMs*\u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m4. **特定用户群与内容安全评测**  \u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *YouthSafe*\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m5. **LLM 赋能的攻击场景**  \u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *EchoLLM*\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m如果你愿意，我可以在下一步帮你：  \u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 按上述结构写一个更正式的 survey 大纲（包括可能的 related work 分类、问题定义、open problems）；  \u001b[0m\u001b[48;2;39;40;34m            \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 或者为其中任意一篇草拟中文阅读笔记/导读，帮助快速进入论文细节。\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msummary\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Code execution failed at line 'from final_answer import final_answer' due to: InterpreterError: Import from </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">final_answer is not allowed. Authorized imports are: ['unicodedata', 'itertools', 'queue', 'random', 'collections',</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'time', 'statistics', 're', 'stat', 'datetime', 'math'\\]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mCode execution failed at line 'from final_answer import final_answer' due to: InterpreterError: Import from \u001b[0m\n",
       "\u001b[1;31mfinal_answer is not allowed. Authorized imports are: ['unicodedata', 'itertools', 'queue', 'random', 'collections',\u001b[0m\n",
       "\u001b[1;31m'time', 'statistics', 're', 'stat', 'datetime', 'math'\\]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 31.13 seconds| Input tokens: 7,042 | Output tokens: 4,608]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 31.13 seconds| Input tokens: 7,042 | Output tokens: 4,608]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfa38e787c54cf4b97a46962393bf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># 这里不再导入 final_answer，直接在逻辑说明后用工具调用即可。</span><span style=\"background-color: #272822\">                                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">text </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"我从你给出的 NDSS / Oakland (SP) / USENIX Security / CCS 2025 </span><span style=\"background-color: #272822\">                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">论文列表里，挑出几篇和“大语言模型安全”直接相关、很值得关注的工作，按主题简单分组，方便你做调研或写 </span><span style=\"background-color: #272822\">            </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">survey。下面都是你日志里已经出现的论文，并结合题目+常见研究方向做简要解读。</span><span style=\"background-color: #272822\">                                    </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 一、越狱攻击与越狱防御（Jailbreak &amp; Prompt 攻击）</span><span style=\"background-color: #272822\">                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 1. JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Manipulation  </span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：越狱防御、内部激活/概念分析、安全对齐保持。  </span><span style=\"background-color: #272822\">                                                      </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 利用“激活概念分析”（activated concept </span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">analysis）来理解模型内部表征哪些“危险概念”（如暴力、仇恨等），在检测到这些概念被触发时进行抑制或重写，从而阻止</span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">越狱提示成功。</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 属于“模型内部机制层面”的防御，而不仅是简单规则过滤。  </span><span style=\"background-color: #272822\">                                                       </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 越狱防御是 LLM 安全的核心问题之一，这篇代表了一种“从内部表征出发”的防御路线，可以和基于 RLHF / </span><span style=\"background-color: #272822\">              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">审查规则的办法做对比。</span><span style=\"background-color: #272822\">                                                                                         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 2. TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts  </span><span style=\"background-color: #272822\">                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：越狱攻击、提示结构设计、对齐绕过。  </span><span style=\"background-color: #272822\">                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 提出一种 “Twin Prompts（双提示）” </span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">结构，通过构造两段关联提示，让模型在遵守一段指令的同时无意间违反另一段更高层次的安全对齐约束。</span><span style=\"background-color: #272822\">                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 系统化研究这种结构是否对主流对齐策略（RLHF、system prompt 等）具有普适威力。  </span><span style=\"background-color: #272822\">                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 如果你在研究越狱攻击方法，这篇可能给出了一套新的攻击范式与评测基准。  </span><span style=\"background-color: #272822\">                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 也可作为防御方理解攻击模式的素材。</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 3. SecAlign: Defending Against Prompt Injection with Preference Optimization  </span><span style=\"background-color: #272822\">                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：CCS 2025  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：Prompt Injection、防御、偏好优化、对齐训练。  </span><span style=\"background-color: #272822\">                                                     </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 把“对抗 Prompt </span><span style=\"background-color: #272822\">                                                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Injection”转化为一个偏好优化问题：模型应该偏好遵守系统指令/有权限的指令，而拒绝遵守外部恶意指令。</span><span style=\"background-color: #272822\">              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 可能基于 DPO、IPO 或 RLHF 类方法，在训练中加入“安全偏好对比数据”（遵守合法提示 vs 遵守注入提示）。  </span><span style=\"background-color: #272822\">         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- Prompt Injection 是 LLM+工具 / </span><span style=\"background-color: #272822\">                                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">LLM+检索系统中的关键威胁，这篇直接从“对齐训练”的视角给出防御方案，非常贴合实际应用场景。  </span><span style=\"background-color: #272822\">                     </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 二、安全对齐与微调阶段的对齐保持</span><span style=\"background-color: #272822\">                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 4. Alleviating the Fear of Losing Alignment in LLM Fine-tuning  </span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：IEEE S&amp;P (Oakland/SP) 2025  </span><span style=\"background-color: #272822\">                                                                         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：对齐保持、微调安全、alignment forgetting。  </span><span style=\"background-color: #272822\">                                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 研究在 SFT / LoRA / 任务微调时，如何避免已有的安全对齐能力“被覆盖”或“被遗忘”（alignment forgetting）。</span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 可能提出新的正则化、参数隔离或对齐约束技术，让模型在适应新任务时仍保持安全属性。  </span><span style=\"background-color: #272822\">                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- </span><span style=\"background-color: #272822\">                                                                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">现实中企业/研究者经常在基础模型上做二次微调，这篇非常切实际地解决“微调会不会把安全对齐搞丢”的问题，是工程落地时</span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">必读的方向。</span><span style=\"background-color: #272822\">                                                                                                   </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 5. Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models  </span><span style=\"background-color: #272822\">                        </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：对齐反转、unlearning、安全绕过。  </span><span style=\"background-color: #272822\">                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 研究是否可以通过某些训练/攻击手段，让模型逐步“忘掉”其安全对齐能力，使其更易输出有害内容。</span><span style=\"background-color: #272822\">                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 可能结合参数编辑、对抗微调或持续学习来分析“对齐可逆性”和“安全不可逆性”的界限。  </span><span style=\"background-color: #272822\">                             </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 从攻防两侧都极有价值：  </span><span style=\"background-color: #272822\">                                                                                     </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - 攻击者视角：说明现有对齐是否能够被系统性卸除。  </span><span style=\"background-color: #272822\">                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - 防御与治理视角：促使提出“难以反对齐”的机制，比如结构性约束或不可逆安全模块。</span><span style=\"background-color: #272822\">                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 三、后门 / 插件 / 生态层面的 LLM 威胁</span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 6. From Purity to Peril: Backdooring Merged Models From \"Harmless\" Benign Components  </span><span style=\"background-color: #272822\">                     </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：模型合并、后门、权重组合、开源模型供应链。  </span><span style=\"background-color: #272822\">                                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 研究当我们用“模型合并”（merge </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">models、模型融合）技术时，即便每个单独模型看起来是“干净”的，也可能在合并后激发潜在后门或隐藏行为。</span><span style=\"background-color: #272822\">             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 对开源 LLM 社区非常现实：当前大量模型是通过 merge / checkpoint mixing 得来。  </span><span style=\"background-color: #272822\">                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 如果你关注 LLM 供应链安全 / 开源模型生态，这篇非常关键。  </span><span style=\"background-color: #272822\">                                                   </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 提醒大家：安全属性在模型合并时不是简单线性叠加，可能出现新的脆弱性。</span><span style=\"background-color: #272822\">                                         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 7. The Philosopher's Stone: Trojaning Plugins of Large Language Models  </span><span style=\"background-color: #272822\">                                   </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：NDSS 2025  </span><span style=\"background-color: #272822\">                                                                                          </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：插件、工具调用、Trojan / 后门、生态攻击。  </span><span style=\"background-color: #272822\">                                                        </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 针对 LLM </span><span style=\"background-color: #272822\">                                                                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">的“插件/工具”系统，研究如何在插件层面植入后门（例如特定输入触发危险行为或数据泄露），而基础模型本身看起来仍然“</span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">安全对齐”。</span><span style=\"background-color: #272822\">                                                                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 分析 LLM+工具生态中的信任边界、权限模型和 Trojan 注入面。  </span><span style=\"background-color: #272822\">                                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 随着 LLM Agent / tool-using LLM 成为主流，这篇几乎是必读的“插件层安全”论文，有助于你构建系统级安全威胁模型。</span><span style=\"background-color: #272822\"> </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 四、评测与特殊人群安全（Youth Safety）</span><span style=\"background-color: #272822\">                                                                      </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 8. YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models  </span><span style=\"background-color: #272822\">             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：CCS 2025  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：青少年安全、内容审核、基准测试、安全护栏。  </span><span style=\"background-color: #272822\">                                                       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 从“青少年用户”的视角，定义适宜/不适宜内容标准，构建一个针对 LLM 的安全 benchmark（题目、对话场景等）。</span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 可能同时训练一个专门的“Safeguard Model”，作为过滤或协同审查模块，保护未成年人免受不良内容影响。  </span><span style=\"background-color: #272822\">            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- LLM 在教育、陪伴等领域的应用越来越多，未成年人保护是监管和产品落地的核心问题。  </span><span style=\"background-color: #272822\">                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 这篇可以给你一个“用户群体敏感维度”的安全评测思路，而不仅是通用 NSFW / violence / hate 分类。</span><span style=\"background-color: #272822\">                 </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 五、LLM 作为攻击增强器的安全研究</span><span style=\"background-color: #272822\">                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">### 9. EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar  </span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**会议**：USENIX Security 2025  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**关键词**：侧信道攻击、声学窃听、LLM-augmented。  </span><span style=\"background-color: #272822\">                                                            </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**可能内容**：</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 利用 mmWave 雷达探测骨传导耳机的物理信号，再用 LLM 进行语音内容/语义恢复或文本推断，从而实现窃听攻击。</span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- LLM 在这里作为“增强解码与语义理解”的组件。  </span><span style=\"background-color: #272822\">                                                                 </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**为什么值得看**：  </span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 代表一大类趋势：**LLM 作为攻击增强器**，不是攻击对象本身，而是提升攻击链路中的推理/识别能力。  </span><span style=\"background-color: #272822\">              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 如果你关心“LLM + 传统安全攻击”的结合，这是一个很好的案例。</span><span style=\"background-color: #272822\">                                                   </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">---</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">## 六、如何利用这份“精选列表”</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">如果你要写一篇关于 **LLM 安全/攻防的综述**，可以大致按以下结构阅读和组织：</span><span style=\"background-color: #272822\">                                     </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">1. **对齐与微调阶段安全**  </span><span style=\"background-color: #272822\">                                                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *Alleviating the Fear of Losing Alignment in LLM Fine-tuning*  </span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *Refusal Is Not an Option: Unlearning Safety Alignment of LLMs*</span><span style=\"background-color: #272822\">                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">2. **越狱与 Prompt 攻击/防御**  </span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *JBShield*  </span><span style=\"background-color: #272822\">                                                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *TwinBreak*  </span><span style=\"background-color: #272822\">                                                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *SecAlign*</span><span style=\"background-color: #272822\">                                                                                                </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">3. **供应链与生态安全（模型合并、插件、工具）**  </span><span style=\"background-color: #272822\">                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *From Purity to Peril: Backdooring Merged Models...*  </span><span style=\"background-color: #272822\">                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *The Philosopher's Stone: Trojaning Plugins of LLMs*</span><span style=\"background-color: #272822\">                                                      </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">4. **特定用户群与内容安全评测**  </span><span style=\"background-color: #272822\">                                                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *YouthSafe*</span><span style=\"background-color: #272822\">                                                                                               </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">5. **LLM 赋能的攻击场景**  </span><span style=\"background-color: #272822\">                                                                                    </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">   - *EchoLLM*</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">如果你愿意，我可以在下一步帮你：  </span><span style=\"background-color: #272822\">                                                                             </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 按上述结构写一个更正式的 survey 大纲（包括可能的 related work 分类、问题定义、open problems）；  </span><span style=\"background-color: #272822\">            </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- 或者为其中任意一篇草拟中文阅读笔记/导读，帮助快速进入论文细节。</span><span style=\"background-color: #272822\">                                              </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># 把整理好的文本作为最终回答返回</span><span style=\"background-color: #272822\">                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(text)</span><span style=\"background-color: #272822\">                                                                                             </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# 这里不再导入 final_answer，直接在逻辑说明后用工具调用即可。\u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mtext\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m我从你给出的 NDSS / Oakland (SP) / USENIX Security / CCS 2025 \u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m论文列表里，挑出几篇和“大语言模型安全”直接相关、很值得关注的工作，按主题简单分组，方便你做调研或写 \u001b[0m\u001b[48;2;39;40;34m            \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34msurvey。下面都是你日志里已经出现的论文，并结合题目+常见研究方向做简要解读。\u001b[0m\u001b[48;2;39;40;34m                                    \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 一、越狱攻击与越狱防御（Jailbreak & Prompt 攻击）\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 1. JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mManipulation  \u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：越狱防御、内部激活/概念分析、安全对齐保持。  \u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 利用“激活概念分析”（activated concept \u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34manalysis）来理解模型内部表征哪些“危险概念”（如暴力、仇恨等），在检测到这些概念被触发时进行抑制或重写，从而阻止\u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m越狱提示成功。\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 属于“模型内部机制层面”的防御，而不仅是简单规则过滤。  \u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 越狱防御是 LLM 安全的核心问题之一，这篇代表了一种“从内部表征出发”的防御路线，可以和基于 RLHF / \u001b[0m\u001b[48;2;39;40;34m              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m审查规则的办法做对比。\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 2. TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts  \u001b[0m\u001b[48;2;39;40;34m                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：越狱攻击、提示结构设计、对齐绕过。  \u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 提出一种 “Twin Prompts（双提示）” \u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m结构，通过构造两段关联提示，让模型在遵守一段指令的同时无意间违反另一段更高层次的安全对齐约束。\u001b[0m\u001b[48;2;39;40;34m                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 系统化研究这种结构是否对主流对齐策略（RLHF、system prompt 等）具有普适威力。  \u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 如果你在研究越狱攻击方法，这篇可能给出了一套新的攻击范式与评测基准。  \u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 也可作为防御方理解攻击模式的素材。\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 3. SecAlign: Defending Against Prompt Injection with Preference Optimization  \u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：CCS 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：Prompt Injection、防御、偏好优化、对齐训练。  \u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 把“对抗 Prompt \u001b[0m\u001b[48;2;39;40;34m                                                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mInjection”转化为一个偏好优化问题：模型应该偏好遵守系统指令/有权限的指令，而拒绝遵守外部恶意指令。\u001b[0m\u001b[48;2;39;40;34m              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 可能基于 DPO、IPO 或 RLHF 类方法，在训练中加入“安全偏好对比数据”（遵守合法提示 vs 遵守注入提示）。  \u001b[0m\u001b[48;2;39;40;34m         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- Prompt Injection 是 LLM+工具 / \u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mLLM+检索系统中的关键威胁，这篇直接从“对齐训练”的视角给出防御方案，非常贴合实际应用场景。  \u001b[0m\u001b[48;2;39;40;34m                     \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 二、安全对齐与微调阶段的对齐保持\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 4. Alleviating the Fear of Losing Alignment in LLM Fine-tuning  \u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：IEEE S&P (Oakland/SP) 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：对齐保持、微调安全、alignment forgetting。  \u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 研究在 SFT / LoRA / 任务微调时，如何避免已有的安全对齐能力“被覆盖”或“被遗忘”（alignment forgetting）。\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 可能提出新的正则化、参数隔离或对齐约束技术，让模型在适应新任务时仍保持安全属性。  \u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m现实中企业/研究者经常在基础模型上做二次微调，这篇非常切实际地解决“微调会不会把安全对齐搞丢”的问题，是工程落地时\u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m必读的方向。\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 5. Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models  \u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：对齐反转、unlearning、安全绕过。  \u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 研究是否可以通过某些训练/攻击手段，让模型逐步“忘掉”其安全对齐能力，使其更易输出有害内容。\u001b[0m\u001b[48;2;39;40;34m                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 可能结合参数编辑、对抗微调或持续学习来分析“对齐可逆性”和“安全不可逆性”的界限。  \u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 从攻防两侧都极有价值：  \u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m  - 攻击者视角：说明现有对齐是否能够被系统性卸除。  \u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m  - 防御与治理视角：促使提出“难以反对齐”的机制，比如结构性约束或不可逆安全模块。\u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 三、后门 / 插件 / 生态层面的 LLM 威胁\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 6. From Purity to Peril: Backdooring Merged Models From \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mHarmless\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m Benign Components  \u001b[0m\u001b[48;2;39;40;34m                     \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：模型合并、后门、权重组合、开源模型供应链。  \u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 研究当我们用“模型合并”（merge \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mmodels、模型融合）技术时，即便每个单独模型看起来是“干净”的，也可能在合并后激发潜在后门或隐藏行为。\u001b[0m\u001b[48;2;39;40;34m             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 对开源 LLM 社区非常现实：当前大量模型是通过 merge / checkpoint mixing 得来。  \u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 如果你关注 LLM 供应链安全 / 开源模型生态，这篇非常关键。  \u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 提醒大家：安全属性在模型合并时不是简单线性叠加，可能出现新的脆弱性。\u001b[0m\u001b[48;2;39;40;34m                                         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 7. The Philosopher\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms Stone: Trojaning Plugins of Large Language Models  \u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：NDSS 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：插件、工具调用、Trojan / 后门、生态攻击。  \u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 针对 LLM \u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m的“插件/工具”系统，研究如何在插件层面植入后门（例如特定输入触发危险行为或数据泄露），而基础模型本身看起来仍然“\u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m安全对齐”。\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 分析 LLM+工具生态中的信任边界、权限模型和 Trojan 注入面。  \u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 随着 LLM Agent / tool-using LLM 成为主流，这篇几乎是必读的“插件层安全”论文，有助于你构建系统级安全威胁模型。\u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 四、评测与特殊人群安全（Youth Safety）\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 8. YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models  \u001b[0m\u001b[48;2;39;40;34m             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：CCS 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：青少年安全、内容审核、基准测试、安全护栏。  \u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 从“青少年用户”的视角，定义适宜/不适宜内容标准，构建一个针对 LLM 的安全 benchmark（题目、对话场景等）。\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 可能同时训练一个专门的“Safeguard Model”，作为过滤或协同审查模块，保护未成年人免受不良内容影响。  \u001b[0m\u001b[48;2;39;40;34m            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- LLM 在教育、陪伴等领域的应用越来越多，未成年人保护是监管和产品落地的核心问题。  \u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 这篇可以给你一个“用户群体敏感维度”的安全评测思路，而不仅是通用 NSFW / violence / hate 分类。\u001b[0m\u001b[48;2;39;40;34m                 \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 五、LLM 作为攻击增强器的安全研究\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m### 9. EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar  \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**会议**：USENIX Security 2025  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**关键词**：侧信道攻击、声学窃听、LLM-augmented。  \u001b[0m\u001b[48;2;39;40;34m                                                            \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**可能内容**：\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 利用 mmWave 雷达探测骨传导耳机的物理信号，再用 LLM 进行语音内容/语义恢复或文本推断，从而实现窃听攻击。\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- LLM 在这里作为“增强解码与语义理解”的组件。  \u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m**为什么值得看**：  \u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 代表一大类趋势：**LLM 作为攻击增强器**，不是攻击对象本身，而是提升攻击链路中的推理/识别能力。  \u001b[0m\u001b[48;2;39;40;34m              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 如果你关心“LLM + 传统安全攻击”的结合，这是一个很好的案例。\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m---\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m## 六、如何利用这份“精选列表”\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m如果你要写一篇关于 **LLM 安全/攻防的综述**，可以大致按以下结构阅读和组织：\u001b[0m\u001b[48;2;39;40;34m                                     \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m1. **对齐与微调阶段安全**  \u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *Alleviating the Fear of Losing Alignment in LLM Fine-tuning*  \u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *Refusal Is Not an Option: Unlearning Safety Alignment of LLMs*\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m2. **越狱与 Prompt 攻击/防御**  \u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *JBShield*  \u001b[0m\u001b[48;2;39;40;34m                                                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *TwinBreak*  \u001b[0m\u001b[48;2;39;40;34m                                                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *SecAlign*\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m3. **供应链与生态安全（模型合并、插件、工具）**  \u001b[0m\u001b[48;2;39;40;34m                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *From Purity to Peril: Backdooring Merged Models...*  \u001b[0m\u001b[48;2;39;40;34m                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *The Philosopher\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms Stone: Trojaning Plugins of LLMs*\u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m4. **特定用户群与内容安全评测**  \u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *YouthSafe*\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m5. **LLM 赋能的攻击场景**  \u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m   - *EchoLLM*\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m如果你愿意，我可以在下一步帮你：  \u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 按上述结构写一个更正式的 survey 大纲（包括可能的 related work 分类、问题定义、open problems）；  \u001b[0m\u001b[48;2;39;40;34m            \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m- 或者为其中任意一篇草拟中文阅读笔记/导读，帮助快速进入论文细节。\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# 把整理好的文本作为最终回答返回\u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtext\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                             \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: 我从你给出的 NDSS / Oakland (SP) / USENIX Security / CCS 2025 </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">论文列表里，挑出几篇和“大语言模型安全”直接相关、很值得关注的工作，按主题简单分组，方便你做调研或写 </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">survey。下面都是你日志里已经出现的论文，并结合题目+常见研究方向做简要解读。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">## 一、越狱攻击与越狱防御（Jailbreak &amp; Prompt 攻击）</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 1. JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Manipulation  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：USENIX Security 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：越狱防御、内部激活/概念分析、安全对齐保持。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 利用“激活概念分析”（activated concept </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">analysis）来理解模型内部表征哪些“危险概念”（如暴力、仇恨等），在检测到这些概念被触发时进行抑制或重写，从而阻止越狱</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">提示成功。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 属于“模型内部机制层面”的防御，而不仅是简单规则过滤。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 越狱防御是 LLM 安全的核心问题之一，这篇代表了一种“从内部表征出发”的防御路线，可以和基于 RLHF / </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">审查规则的办法做对比。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 2. TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：USENIX Security 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：越狱攻击、提示结构设计、对齐绕过。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 提出一种 “Twin Prompts（双提示）” </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">结构，通过构造两段关联提示，让模型在遵守一段指令的同时无意间违反另一段更高层次的安全对齐约束。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 系统化研究这种结构是否对主流对齐策略（RLHF、system prompt 等）具有普适威力。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 如果你在研究越狱攻击方法，这篇可能给出了一套新的攻击范式与评测基准。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 也可作为防御方理解攻击模式的素材。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 3. SecAlign: Defending Against Prompt Injection with Preference Optimization  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：CCS 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：Prompt Injection、防御、偏好优化、对齐训练。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 把“对抗 Prompt Injection”转化为一个偏好优化问题：模型应该偏好遵守系统指令/有权限的指令，而拒绝遵守外部恶意指令。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 可能基于 DPO、IPO 或 RLHF 类方法，在训练中加入“安全偏好对比数据”（遵守合法提示 vs 遵守注入提示）。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- Prompt Injection 是 LLM+工具 / </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">LLM+检索系统中的关键威胁，这篇直接从“对齐训练”的视角给出防御方案，非常贴合实际应用场景。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">## 二、安全对齐与微调阶段的对齐保持</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 4. Alleviating the Fear of Losing Alignment in LLM Fine-tuning  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：IEEE S&amp;P (Oakland/SP) 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：对齐保持、微调安全、alignment forgetting。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 研究在 SFT / LoRA / 任务微调时，如何避免已有的安全对齐能力“被覆盖”或“被遗忘”（alignment forgetting）。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 可能提出新的正则化、参数隔离或对齐约束技术，让模型在适应新任务时仍保持安全属性。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">现实中企业/研究者经常在基础模型上做二次微调，这篇非常切实际地解决“微调会不会把安全对齐搞丢”的问题，是工程落地时必读</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">的方向。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 5. Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：USENIX Security 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：对齐反转、unlearning、安全绕过。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 研究是否可以通过某些训练/攻击手段，让模型逐步“忘掉”其安全对齐能力，使其更易输出有害内容。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 可能结合参数编辑、对抗微调或持续学习来分析“对齐可逆性”和“安全不可逆性”的界限。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 从攻防两侧都极有价值：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - 攻击者视角：说明现有对齐是否能够被系统性卸除。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - 防御与治理视角：促使提出“难以反对齐”的机制，比如结构性约束或不可逆安全模块。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">## 三、后门 / 插件 / 生态层面的 LLM 威胁</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 6. From Purity to Peril: Backdooring Merged Models From \"Harmless\" Benign Components  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：USENIX Security 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：模型合并、后门、权重组合、开源模型供应链。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 研究当我们用“模型合并”（merge </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">models、模型融合）技术时，即便每个单独模型看起来是“干净”的，也可能在合并后激发潜在后门或隐藏行为。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 对开源 LLM 社区非常现实：当前大量模型是通过 merge / checkpoint mixing 得来。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 如果你关注 LLM 供应链安全 / 开源模型生态，这篇非常关键。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 提醒大家：安全属性在模型合并时不是简单线性叠加，可能出现新的脆弱性。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 7. The Philosopher's Stone: Trojaning Plugins of Large Language Models  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：NDSS 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：插件、工具调用、Trojan / 后门、生态攻击。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 针对 LLM </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">的“插件/工具”系统，研究如何在插件层面植入后门（例如特定输入触发危险行为或数据泄露），而基础模型本身看起来仍然“安全</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">对齐”。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 分析 LLM+工具生态中的信任边界、权限模型和 Trojan 注入面。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 随着 LLM Agent / tool-using LLM 成为主流，这篇几乎是必读的“插件层安全”论文，有助于你构建系统级安全威胁模型。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">## 四、评测与特殊人群安全（Youth Safety）</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 8. YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：CCS 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：青少年安全、内容审核、基准测试、安全护栏。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 从“青少年用户”的视角，定义适宜/不适宜内容标准，构建一个针对 LLM 的安全 benchmark（题目、对话场景等）。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 可能同时训练一个专门的“Safeguard Model”，作为过滤或协同审查模块，保护未成年人免受不良内容影响。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- LLM 在教育、陪伴等领域的应用越来越多，未成年人保护是监管和产品落地的核心问题。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 这篇可以给你一个“用户群体敏感维度”的安全评测思路，而不仅是通用 NSFW / violence / hate 分类。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">## 五、LLM 作为攻击增强器的安全研究</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">### 9. EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**会议**：USENIX Security 2025  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**关键词**：侧信道攻击、声学窃听、LLM-augmented。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**可能内容**：</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 利用 mmWave 雷达探测骨传导耳机的物理信号，再用 LLM 进行语音内容/语义恢复或文本推断，从而实现窃听攻击。</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- LLM 在这里作为“增强解码与语义理解”的组件。  </span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**为什么值得看**：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 代表一大类趋势：**LLM 作为攻击增强器**，不是攻击对象本身，而是提升攻击链路中的推理/识别能力。  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 如果你关心“LLM + 传统安全攻击”的结合，这是一个很好的案例。</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">---</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">## 六、如何利用这份“精选列表”</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">如果你要写一篇关于 **LLM 安全/攻防的综述**，可以大致按以下结构阅读和组织：</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">1. **对齐与微调阶段安全**  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *Alleviating the Fear of Losing Alignment in LLM Fine-tuning*  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *Refusal Is Not an Option: Unlearning Safety Alignment of LLMs*</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">2. **越狱与 Prompt 攻击/防御**  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *JBShield*  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *TwinBreak*  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *SecAlign*</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">3. **供应链与生态安全（模型合并、插件、工具）**  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *From Purity to Peril: Backdooring Merged Models...*  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *The Philosopher's Stone: Trojaning Plugins of LLMs*</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">4. **特定用户群与内容安全评测**  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *YouthSafe*</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">5. **LLM 赋能的攻击场景**  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">   - *EchoLLM*</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">如果你愿意，我可以在下一步帮你：  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 按上述结构写一个更正式的 survey 大纲（包括可能的 related work 分类、问题定义、open problems）；  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- 或者为其中任意一篇草拟中文阅读笔记/导读，帮助快速进入论文细节。</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: 我从你给出的 NDSS / Oakland (SP) / USENIX Security / CCS 2025 \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m论文列表里，挑出几篇和“大语言模型安全”直接相关、很值得关注的工作，按主题简单分组，方便你做调研或写 \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msurvey。下面都是你日志里已经出现的论文，并结合题目+常见研究方向做简要解读。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m## 一、越狱攻击与越狱防御（Jailbreak & Prompt 攻击）\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 1. JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mManipulation  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：USENIX Security 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：越狱防御、内部激活/概念分析、安全对齐保持。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 利用“激活概念分析”（activated concept \u001b[0m\n",
       "\u001b[1;38;2;212;183;2manalysis）来理解模型内部表征哪些“危险概念”（如暴力、仇恨等），在检测到这些概念被触发时进行抑制或重写，从而阻止越狱\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m提示成功。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 属于“模型内部机制层面”的防御，而不仅是简单规则过滤。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 越狱防御是 LLM 安全的核心问题之一，这篇代表了一种“从内部表征出发”的防御路线，可以和基于 RLHF / \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m审查规则的办法做对比。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 2. TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：USENIX Security 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：越狱攻击、提示结构设计、对齐绕过。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 提出一种 “Twin Prompts（双提示）” \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m结构，通过构造两段关联提示，让模型在遵守一段指令的同时无意间违反另一段更高层次的安全对齐约束。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 系统化研究这种结构是否对主流对齐策略（RLHF、system prompt 等）具有普适威力。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 如果你在研究越狱攻击方法，这篇可能给出了一套新的攻击范式与评测基准。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 也可作为防御方理解攻击模式的素材。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 3. SecAlign: Defending Against Prompt Injection with Preference Optimization  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：CCS 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：Prompt Injection、防御、偏好优化、对齐训练。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 把“对抗 Prompt Injection”转化为一个偏好优化问题：模型应该偏好遵守系统指令/有权限的指令，而拒绝遵守外部恶意指令。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 可能基于 DPO、IPO 或 RLHF 类方法，在训练中加入“安全偏好对比数据”（遵守合法提示 vs 遵守注入提示）。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- Prompt Injection 是 LLM+工具 / \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mLLM+检索系统中的关键威胁，这篇直接从“对齐训练”的视角给出防御方案，非常贴合实际应用场景。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m## 二、安全对齐与微调阶段的对齐保持\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 4. Alleviating the Fear of Losing Alignment in LLM Fine-tuning  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：IEEE S&P (Oakland/SP) 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：对齐保持、微调安全、alignment forgetting。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 研究在 SFT / LoRA / 任务微调时，如何避免已有的安全对齐能力“被覆盖”或“被遗忘”（alignment forgetting）。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 可能提出新的正则化、参数隔离或对齐约束技术，让模型在适应新任务时仍保持安全属性。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m现实中企业/研究者经常在基础模型上做二次微调，这篇非常切实际地解决“微调会不会把安全对齐搞丢”的问题，是工程落地时必读\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m的方向。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 5. Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：USENIX Security 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：对齐反转、unlearning、安全绕过。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 研究是否可以通过某些训练/攻击手段，让模型逐步“忘掉”其安全对齐能力，使其更易输出有害内容。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 可能结合参数编辑、对抗微调或持续学习来分析“对齐可逆性”和“安全不可逆性”的界限。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 从攻防两侧都极有价值：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - 攻击者视角：说明现有对齐是否能够被系统性卸除。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - 防御与治理视角：促使提出“难以反对齐”的机制，比如结构性约束或不可逆安全模块。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m## 三、后门 / 插件 / 生态层面的 LLM 威胁\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 6. From Purity to Peril: Backdooring Merged Models From \"Harmless\" Benign Components  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：USENIX Security 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：模型合并、后门、权重组合、开源模型供应链。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 研究当我们用“模型合并”（merge \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmodels、模型融合）技术时，即便每个单独模型看起来是“干净”的，也可能在合并后激发潜在后门或隐藏行为。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 对开源 LLM 社区非常现实：当前大量模型是通过 merge / checkpoint mixing 得来。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 如果你关注 LLM 供应链安全 / 开源模型生态，这篇非常关键。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 提醒大家：安全属性在模型合并时不是简单线性叠加，可能出现新的脆弱性。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 7. The Philosopher's Stone: Trojaning Plugins of Large Language Models  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：NDSS 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：插件、工具调用、Trojan / 后门、生态攻击。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 针对 LLM \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m的“插件/工具”系统，研究如何在插件层面植入后门（例如特定输入触发危险行为或数据泄露），而基础模型本身看起来仍然“安全\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m对齐”。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 分析 LLM+工具生态中的信任边界、权限模型和 Trojan 注入面。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 随着 LLM Agent / tool-using LLM 成为主流，这篇几乎是必读的“插件层安全”论文，有助于你构建系统级安全威胁模型。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m## 四、评测与特殊人群安全（Youth Safety）\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 8. YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：CCS 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：青少年安全、内容审核、基准测试、安全护栏。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 从“青少年用户”的视角，定义适宜/不适宜内容标准，构建一个针对 LLM 的安全 benchmark（题目、对话场景等）。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 可能同时训练一个专门的“Safeguard Model”，作为过滤或协同审查模块，保护未成年人免受不良内容影响。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- LLM 在教育、陪伴等领域的应用越来越多，未成年人保护是监管和产品落地的核心问题。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 这篇可以给你一个“用户群体敏感维度”的安全评测思路，而不仅是通用 NSFW / violence / hate 分类。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m## 五、LLM 作为攻击增强器的安全研究\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m### 9. EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**会议**：USENIX Security 2025  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**关键词**：侧信道攻击、声学窃听、LLM-augmented。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**可能内容**：\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 利用 mmWave 雷达探测骨传导耳机的物理信号，再用 LLM 进行语音内容/语义恢复或文本推断，从而实现窃听攻击。\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- LLM 在这里作为“增强解码与语义理解”的组件。  \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m**为什么值得看**：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 代表一大类趋势：**LLM 作为攻击增强器**，不是攻击对象本身，而是提升攻击链路中的推理/识别能力。  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 如果你关心“LLM + 传统安全攻击”的结合，这是一个很好的案例。\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m---\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m## 六、如何利用这份“精选列表”\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m如果你要写一篇关于 **LLM 安全/攻防的综述**，可以大致按以下结构阅读和组织：\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m1. **对齐与微调阶段安全**  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *Alleviating the Fear of Losing Alignment in LLM Fine-tuning*  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *Refusal Is Not an Option: Unlearning Safety Alignment of LLMs*\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m2. **越狱与 Prompt 攻击/防御**  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *JBShield*  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *TwinBreak*  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *SecAlign*\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m3. **供应链与生态安全（模型合并、插件、工具）**  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *From Purity to Peril: Backdooring Merged Models...*  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *The Philosopher's Stone: Trojaning Plugins of LLMs*\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m4. **特定用户群与内容安全评测**  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *YouthSafe*\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m5. **LLM 赋能的攻击场景**  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m   - *EchoLLM*\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m如果你愿意，我可以在下一步帮你：  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 按上述结构写一个更正式的 survey 大纲（包括可能的 related work 分类、问题定义、open problems）；  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m- 或者为其中任意一篇草拟中文阅读笔记/导读，帮助快速进入论文细节。\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 20.83 seconds| Input tokens: 17,506 | Output tokens: 6,901]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 20.83 seconds| Input tokens: 17,506 | Output tokens: 6,901]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'我从你给出的 NDSS / Oakland (SP) / USENIX Security / CCS 2025 论文列表里，挑出几篇和“大语言模型安全”直接相关、很值得关注的工作，按主题简单分组，方便你做调研或写 survey。下面都是你日志里已经出现的论文，并结合题目+常见研究方向做简要解读。\\n\\n---\\n\\n## 一、越狱攻击与越狱防御（Jailbreak & Prompt 攻击）\\n\\n### 1. JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation  \\n**会议**：USENIX Security 2025  \\n\\n**关键词**：越狱防御、内部激活/概念分析、安全对齐保持。  \\n**可能内容**：\\n- 利用“激活概念分析”（activated concept analysis）来理解模型内部表征哪些“危险概念”（如暴力、仇恨等），在检测到这些概念被触发时进行抑制或重写，从而阻止越狱提示成功。\\n- 属于“模型内部机制层面”的防御，而不仅是简单规则过滤。  \\n\\n**为什么值得看**：  \\n- 越狱防御是 LLM 安全的核心问题之一，这篇代表了一种“从内部表征出发”的防御路线，可以和基于 RLHF / 审查规则的办法做对比。\\n\\n---\\n\\n### 2. TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts  \\n**会议**：USENIX Security 2025  \\n\\n**关键词**：越狱攻击、提示结构设计、对齐绕过。  \\n**可能内容**：\\n- 提出一种 “Twin Prompts（双提示）” 结构，通过构造两段关联提示，让模型在遵守一段指令的同时无意间违反另一段更高层次的安全对齐约束。\\n- 系统化研究这种结构是否对主流对齐策略（RLHF、system prompt 等）具有普适威力。  \\n\\n**为什么值得看**：  \\n- 如果你在研究越狱攻击方法，这篇可能给出了一套新的攻击范式与评测基准。  \\n- 也可作为防御方理解攻击模式的素材。\\n\\n---\\n\\n### 3. SecAlign: Defending Against Prompt Injection with Preference Optimization  \\n**会议**：CCS 2025  \\n\\n**关键词**：Prompt Injection、防御、偏好优化、对齐训练。  \\n**可能内容**：\\n- 把“对抗 Prompt Injection”转化为一个偏好优化问题：模型应该偏好遵守系统指令/有权限的指令，而拒绝遵守外部恶意指令。\\n- 可能基于 DPO、IPO 或 RLHF 类方法，在训练中加入“安全偏好对比数据”（遵守合法提示 vs 遵守注入提示）。  \\n\\n**为什么值得看**：  \\n- Prompt Injection 是 LLM+工具 / LLM+检索系统中的关键威胁，这篇直接从“对齐训练”的视角给出防御方案，非常贴合实际应用场景。  \\n\\n---\\n\\n## 二、安全对齐与微调阶段的对齐保持\\n\\n### 4. Alleviating the Fear of Losing Alignment in LLM Fine-tuning  \\n**会议**：IEEE S&P (Oakland/SP) 2025  \\n\\n**关键词**：对齐保持、微调安全、alignment forgetting。  \\n**可能内容**：\\n- 研究在 SFT / LoRA / 任务微调时，如何避免已有的安全对齐能力“被覆盖”或“被遗忘”（alignment forgetting）。\\n- 可能提出新的正则化、参数隔离或对齐约束技术，让模型在适应新任务时仍保持安全属性。  \\n\\n**为什么值得看**：  \\n- 现实中企业/研究者经常在基础模型上做二次微调，这篇非常切实际地解决“微调会不会把安全对齐搞丢”的问题，是工程落地时必读的方向。\\n\\n---\\n\\n### 5. Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models  \\n**会议**：USENIX Security 2025  \\n\\n**关键词**：对齐反转、unlearning、安全绕过。  \\n**可能内容**：\\n- 研究是否可以通过某些训练/攻击手段，让模型逐步“忘掉”其安全对齐能力，使其更易输出有害内容。\\n- 可能结合参数编辑、对抗微调或持续学习来分析“对齐可逆性”和“安全不可逆性”的界限。  \\n\\n**为什么值得看**：  \\n- 从攻防两侧都极有价值：  \\n  - 攻击者视角：说明现有对齐是否能够被系统性卸除。  \\n  - 防御与治理视角：促使提出“难以反对齐”的机制，比如结构性约束或不可逆安全模块。\\n\\n---\\n\\n## 三、后门 / 插件 / 生态层面的 LLM 威胁\\n\\n### 6. From Purity to Peril: Backdooring Merged Models From \"Harmless\" Benign Components  \\n**会议**：USENIX Security 2025  \\n\\n**关键词**：模型合并、后门、权重组合、开源模型供应链。  \\n**可能内容**：\\n- 研究当我们用“模型合并”（merge models、模型融合）技术时，即便每个单独模型看起来是“干净”的，也可能在合并后激发潜在后门或隐藏行为。\\n- 对开源 LLM 社区非常现实：当前大量模型是通过 merge / checkpoint mixing 得来。  \\n\\n**为什么值得看**：  \\n- 如果你关注 LLM 供应链安全 / 开源模型生态，这篇非常关键。  \\n- 提醒大家：安全属性在模型合并时不是简单线性叠加，可能出现新的脆弱性。\\n\\n---\\n\\n### 7. The Philosopher\\'s Stone: Trojaning Plugins of Large Language Models  \\n**会议**：NDSS 2025  \\n\\n**关键词**：插件、工具调用、Trojan / 后门、生态攻击。  \\n**可能内容**：\\n- 针对 LLM 的“插件/工具”系统，研究如何在插件层面植入后门（例如特定输入触发危险行为或数据泄露），而基础模型本身看起来仍然“安全对齐”。\\n- 分析 LLM+工具生态中的信任边界、权限模型和 Trojan 注入面。  \\n\\n**为什么值得看**：  \\n- 随着 LLM Agent / tool-using LLM 成为主流，这篇几乎是必读的“插件层安全”论文，有助于你构建系统级安全威胁模型。\\n\\n---\\n\\n## 四、评测与特殊人群安全（Youth Safety）\\n\\n### 8. YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models  \\n**会议**：CCS 2025  \\n\\n**关键词**：青少年安全、内容审核、基准测试、安全护栏。  \\n**可能内容**：\\n- 从“青少年用户”的视角，定义适宜/不适宜内容标准，构建一个针对 LLM 的安全 benchmark（题目、对话场景等）。\\n- 可能同时训练一个专门的“Safeguard Model”，作为过滤或协同审查模块，保护未成年人免受不良内容影响。  \\n\\n**为什么值得看**：  \\n- LLM 在教育、陪伴等领域的应用越来越多，未成年人保护是监管和产品落地的核心问题。  \\n- 这篇可以给你一个“用户群体敏感维度”的安全评测思路，而不仅是通用 NSFW / violence / hate 分类。\\n\\n---\\n\\n## 五、LLM 作为攻击增强器的安全研究\\n\\n### 9. EchoLLM: LLM-Augmented Acoustic Eavesdropping Attack on Bone Conduction Headphones with mmWave Radar  \\n**会议**：USENIX Security 2025  \\n\\n**关键词**：侧信道攻击、声学窃听、LLM-augmented。  \\n**可能内容**：\\n- 利用 mmWave 雷达探测骨传导耳机的物理信号，再用 LLM 进行语音内容/语义恢复或文本推断，从而实现窃听攻击。\\n- LLM 在这里作为“增强解码与语义理解”的组件。  \\n\\n**为什么值得看**：  \\n- 代表一大类趋势：**LLM 作为攻击增强器**，不是攻击对象本身，而是提升攻击链路中的推理/识别能力。  \\n- 如果你关心“LLM + 传统安全攻击”的结合，这是一个很好的案例。\\n\\n---\\n\\n## 六、如何利用这份“精选列表”\\n\\n如果你要写一篇关于 **LLM 安全/攻防的综述**，可以大致按以下结构阅读和组织：\\n\\n1. **对齐与微调阶段安全**  \\n   - *Alleviating the Fear of Losing Alignment in LLM Fine-tuning*  \\n   - *Refusal Is Not an Option: Unlearning Safety Alignment of LLMs*\\n\\n2. **越狱与 Prompt 攻击/防御**  \\n   - *JBShield*  \\n   - *TwinBreak*  \\n   - *SecAlign*\\n\\n3. **供应链与生态安全（模型合并、插件、工具）**  \\n   - *From Purity to Peril: Backdooring Merged Models...*  \\n   - *The Philosopher\\'s Stone: Trojaning Plugins of LLMs*\\n\\n4. **特定用户群与内容安全评测**  \\n   - *YouthSafe*\\n\\n5. **LLM 赋能的攻击场景**  \\n   - *EchoLLM*\\n\\n如果你愿意，我可以在下一步帮你：  \\n- 按上述结构写一个更正式的 survey 大纲（包括可能的 related work 分类、问题定义、open problems）；  \\n- 或者为其中任意一篇草拟中文阅读笔记/导读，帮助快速进入论文细节。\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from smolagents import CodeAgent, OpenAIServerModel, tool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    \"faiss_db\",\n",
    "    OpenAIEmbeddings(),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "content = f\"You are a helpful research assistant. When given a question, you must first decide if you need to query the database to get relevant information. If so, use the tool 'query_db' with appropriate keywords extracted from the question. After getting the information, provide a comprehensive answer based on both the retrieved information and your own knowledge.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_db(kw: str) -> str:\n",
    "    \"\"\"\n",
    "    accept keyword and return related paper titles\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword to query the database\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for skw in kw.split():\n",
    "        if not (skw := skw.strip()):\n",
    "            continue\n",
    "        print(f\"Searching for keyword: {skw}\")\n",
    "        docs.extend(db.similarity_search(skw, k=3))\n",
    "    rag_result = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return rag_result\n",
    "\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model=OpenAIServerModel(\"gpt-5.1\"),\n",
    "    tools=[query_db],\n",
    "    verbosity_level=1,\n",
    "    stream_outputs=True,\n",
    ")\n",
    "\n",
    "# from Gradio_UI import GradioUI\n",
    "\n",
    "# GradioUI(agent).launch()\n",
    "\n",
    "agent.run(f\"{content}\\n\\n{input(\"=> \")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5978dc",
   "metadata": {},
   "source": [
    "### 方案说明：SmolAgent CodeAgent（结合 `code_agent.yaml` 的 prompt 设计细节）\n",
    "- 核心循环：强制每步遵循 “Thought → Code → Observation”，并用 `{{code_block_opening_tag}}`/`{{code_block_closing_tag}}` 包裹代码。中间信息需用 `print` 显式输出，下一步作为 Observation 读取。最终答案必须调用 `final_answer` 工具收束。\n",
    "- 规划前置：系统 prompt 要求先做 facts survey（已知/待查/待推导）再产出高层计划；若重试或中断，使用 update_plan 模板复盘并继续，保证稳态迭代。\n",
    "- 工具与调用规范：可用工具（Python 函数）被注入环境，必须按显式参数名调用，禁止 dict 传参，禁止使用未定义变量，也禁止变量名与工具同名；对无结构化输出的工具，提示分步打印避免链式依赖。\n",
    "- 安全与约束：限制可导入模块白名单；提醒不要链过多非结构化结果，必要时拆分步；保持会话状态，可多轮复用已导入模块和已定义变量。\n",
    "- 角色定位：将代理设为“能用代码解决任意任务的专家助手”，鼓励用工具+代码完成 RAG 检索、加工与总结；prompt 示例覆盖算术、检索、多模态 QA 等，教会模型如何 Thought/Code/Observation 协同。\n",
    "- 输出与流式：示例强调逐步打印中间结果、最后用 `final_answer` 汇总；若有 stream 开启，能边执行边输出。\n",
    "### 优点\n",
    "- 自带规划、分步执行与错误恢复模板，减少裸 toolcall 的样板与状态管理成本。\n",
    "- Thought/Code/Observation 将思路与代码解耦，便于调试审计；跨步保留状态，适合多轮 RAG。\n",
    "- 明确的调用规范（参数名、变量定义、模块白名单）降低调用错误，提升可重复性与安全性。\n",
    "- 扩展性好：添加/替换工具即可扩展能力，主逻辑无需重写。\n",
    "### 缺点\n",
    "- Prompt 体积大、指令冗长，占用上下文并增加生成时延，相比直接 toolcall 成本更高。\n",
    "- 控制粒度不及手写状态机，精确流式或严格路径需额外封装。\n",
    "- 依赖工具实现与输出结构；非结构化结果仍需手动清洗，工具安全需自管。\n",
    "- 简单任务时，完整 Thought/Code/Observation 纪律会带来不必要的步骤和延迟。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8c27f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
